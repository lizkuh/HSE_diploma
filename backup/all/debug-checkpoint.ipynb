{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3937c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from create_subdataset import show_datasets_size, create_subsable_dataset\n",
    "from inference_v3 import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "794449ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1845"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_subsable_dataset(fn_train = \"alpaca-lora/t2c_concode/t2c_answers.json\", \n",
    "                        fn_val = \"alpaca-lora/t2c_concode/t2c_train.json\", \n",
    "                        fn_output = \"alpaca-lora/t2c_concode/t2c_10answers.json\", \n",
    "                        n_samples=10\n",
    "                       )\n",
    "\n",
    "# save dataset in format comfortable to evaluator.py \n",
    "# like here /root/CodeXGLUE/Text-Code/text-to-code/evaluator/answers.json\n",
    "# python /root/CodeXGLUE/Text-Code/text-to-code/evaluator/evaluator.py -a /root/CodeXGLUE/Text-Code/text-to-code/evaluator/answers.json -p {current_pred_name}\n",
    "import json\n",
    "answers = []\n",
    "\n",
    "lst = json.load(open(\"alpaca-lora/t2c_concode/t2c_10answers.json\", \"r\"))\n",
    "for i in lst:\n",
    "    answers.append({\"code\" : i['output'],\n",
    "                    \"nl\" : \"None\"\n",
    "                   }\n",
    "                  )\n",
    "\n",
    "res = '\\n'.join([json.dumps(i) for i in answers])\n",
    "open(\"alpaca-lora/t2c_concode/etalon/10answers.jsonl\", \"w+\").write(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840ec1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|                     |   t2c_answers.json |   t2c_train.json |   t2c_test.json |   t2c_dev.json |   t2c_1000train.json |   t2c_10000train.json |   t2c_10answers.json |\n",
      "|:--------------------|-------------------:|-----------------:|----------------:|---------------:|---------------------:|----------------------:|---------------------:|\n",
      "| t2c_answers.json    |                 99 |               10 |               0 |             99 |                    0 |                     0 |                   10 |\n",
      "| t2c_train.json      |                 10 |            71262 |               0 |            114 |                  981 |                  9138 |                    0 |\n",
      "| t2c_test.json       |                  0 |                0 |               1 |              0 |                    0 |                     0 |                    0 |\n",
      "| t2c_dev.json        |                 99 |              114 |               0 |           1935 |                    0 |                     0 |                   10 |\n",
      "| t2c_1000train.json  |                  0 |              981 |               0 |              0 |                  981 |                   225 |                    0 |\n",
      "| t2c_10000train.json |                  0 |             9138 |               0 |              0 |                  225 |                  9138 |                    0 |\n",
      "| t2c_10answers.json  |                 10 |                0 |               0 |             10 |                    0 |                     0 |                   10 |\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t2c_answers.json</th>\n",
       "      <th>t2c_train.json</th>\n",
       "      <th>t2c_test.json</th>\n",
       "      <th>t2c_dev.json</th>\n",
       "      <th>t2c_1000train.json</th>\n",
       "      <th>t2c_10000train.json</th>\n",
       "      <th>t2c_10answers.json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t2c_answers.json</th>\n",
       "      <td>99</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2c_train.json</th>\n",
       "      <td>10</td>\n",
       "      <td>71262</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>981</td>\n",
       "      <td>9138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2c_test.json</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2c_dev.json</th>\n",
       "      <td>99</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>1935</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2c_1000train.json</th>\n",
       "      <td>0</td>\n",
       "      <td>981</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>981</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2c_10000train.json</th>\n",
       "      <td>0</td>\n",
       "      <td>9138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>9138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t2c_10answers.json</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     t2c_answers.json  t2c_train.json  t2c_test.json   \n",
       "t2c_answers.json                   99              10              0  \\\n",
       "t2c_train.json                     10           71262              0   \n",
       "t2c_test.json                       0               0              1   \n",
       "t2c_dev.json                       99             114              0   \n",
       "t2c_1000train.json                  0             981              0   \n",
       "t2c_10000train.json                 0            9138              0   \n",
       "t2c_10answers.json                 10               0              0   \n",
       "\n",
       "                     t2c_dev.json  t2c_1000train.json  t2c_10000train.json   \n",
       "t2c_answers.json               99                   0                    0  \\\n",
       "t2c_train.json                114                 981                 9138   \n",
       "t2c_test.json                   0                   0                    0   \n",
       "t2c_dev.json                 1935                   0                    0   \n",
       "t2c_1000train.json              0                 981                  225   \n",
       "t2c_10000train.json             0                 225                 9138   \n",
       "t2c_10answers.json             10                   0                    0   \n",
       "\n",
       "                     t2c_10answers.json  \n",
       "t2c_answers.json                     10  \n",
       "t2c_train.json                        0  \n",
       "t2c_test.json                         0  \n",
       "t2c_dev.json                         10  \n",
       "t2c_1000train.json                    0  \n",
       "t2c_10000train.json                   0  \n",
       "t2c_10answers.json                   10  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict = show_datasets_size(input_path = \"alpaca-lora/t2c_concode/\")\n",
    "import pandas as pd\n",
    "pd.DataFrame(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a664f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69af1a4bf8634b13bdb864d27c22083b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "    ### Instruction:\n",
      "    Generate java code\n",
      "returns the namespace uris found in the given xml file \n",
      "\n",
      "    ### Input:\n",
      "     SAXParserFactory factory \n",
      "\n",
      " void setFactory \n",
      " XmlNamespaceFinder createNamespaceFinder \n",
      " SAXParserFactory getFactory\n",
      "\n",
      "    ### Response:\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [01:16<00:00, 76.71s/it]\n",
      "100%|████████████████████████████████████████| 10/10 [00:00<00:00, 64927.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save results at file /root/alpaca-lora/t2c_concode/results/2023-04-29-18_41_20.txt\n",
      "INFO:__main__:BLEU: 19.52, EM: 20.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results_dict = inference(default_model = \"decapoda-research/llama-7b-hf\", \n",
    "                         experiment_name = \"alpaca-lora/t2c_concode_220428_v6\",\n",
    "                         test_dataset = 'alpaca-lora/t2c_concode/t2c_10answers.json',\n",
    "                         fn_answers = \"alpaca-lora/t2c_concode/etalon/10answers.jsonl\",\n",
    "                         batch_size = 10\n",
    "                        )\n",
    "\n",
    "for ind in [0]:\n",
    "    print(f\"\\t\\t[ind={ind}]\")\n",
    "    print('\\n'.join([\"\\t\\t>>\"+k + \"\\n\" + (v if isinstance(v, str) else v[ind]) for k, v in results_dict.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eff6ad73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t[ind=0]\n",
      "\t\t>>metric_string\n",
      "INFO:__main__:BLEU: 19.52, EM: 20.0\n",
      "\n",
      "\t\t>>prompts_list\n",
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "    ### Instruction:\n",
      "    Generate java code\n",
      "returns the namespace uris found in the given xml file \n",
      "\n",
      "    ### Input:\n",
      "     SAXParserFactory factory \n",
      "\n",
      " void setFactory \n",
      " XmlNamespaceFinder createNamespaceFinder \n",
      " SAXParserFactory getFactory\n",
      "\n",
      "    ### Response:\n",
      "    \n",
      "\t\t>>res_list\n",
      "  <unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "    ### Instruction:\n",
      "    Generate java code\n",
      "returns the namespace uris found in the given xml file \n",
      "\n",
      "    ### Input:\n",
      "     SAXParserFactory factory \n",
      "\n",
      " void setFactory \n",
      " XmlNamespaceFinder createNamespaceFinder \n",
      " SAXParserFactory getFactory\n",
      "\n",
      "    ### Response:\n",
      "     Vector function ( File arg0 ) { if ( factory == null ) { factory = createSAXParserFactory ( ) ; } Vector loc0 = new Vector ( ) ; try { SAXParser loc1 = factory. createSAXParser ( ) ; loc1. parse ( arg0, null ) ; } catch ( SAXException loc2 ) { loc2. printStackTrace ( ) ; return null ; } Vector loc0 loc3 = ( ( XmlNamespaceFinder ) arg0. getClass ( ). getName ( ) ). findNamespaceUris ( loc1 ) ; return loc0 ; }\n",
      "\t\t>>predict_list\n",
      "Vector function ( File arg0 ) { if ( factory == null ) { factory = createSAXParserFactory ( ) ; } Vector loc0 = new Vector ( ) ; try { SAXParser loc1 = factory. createSAXParser ( ) ; loc1. parse ( arg0, null ) ; } catch ( SAXException loc2 ) { loc2. printStackTrace ( ) ; return null ; } Vector loc0 loc3 = ( ( XmlNamespaceFinder ) arg0. getClass ( ). getName ( ) ). findNamespaceUris ( loc1 ) ; return loc0 ; }\n"
     ]
    }
   ],
   "source": [
    "for ind in [0]:\n",
    "    print(f\"\\t\\t[ind={ind}]\")\n",
    "    print('\\n'.join([\"\\t\\t>>\"+k + \"\\n\" + (v if isinstance(v, str) else v[ind]) for k, v in results_dict.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e54446a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
