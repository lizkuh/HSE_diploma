{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ac0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All to folder\n",
    "## generate prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c4ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import transformers\n",
    "from peft import PeftModel\n",
    "from transformers import LlamaForCausalLM as LLaMAForCausalLM\n",
    "from transformers import LlamaTokenizer as LLaMATokenizer\n",
    "from peft import prepare_model_for_int8_training, LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "from EvaluateTestSet import EvaluateTestSet\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "def init_lora_model_and_tokenizer(default_model,\n",
    "                             LORA_R,\n",
    "                             LORA_ALPHA,\n",
    "                             LORA_DROPOUT\n",
    "                            ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    model = LLaMAForCausalLM.from_pretrained(\n",
    "    default_model,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    )\n",
    "    tokenizer = LLaMATokenizer.from_pretrained(\n",
    "        default_model, add_eos_token=True\n",
    "    )\n",
    "\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=LORA_R,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    tokenizer.pad_token_id = 0  # unk. we want this to be different from the eos token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "class MyCustomCallback(TensorBoardCallback):\n",
    "    log_bleu_steps_factor = 5\n",
    "    bleu_generation_max_new_tokens = 30\n",
    "    bleu_fn_test_data = \"temp/t2c_answers.json\"\n",
    "    bleu_fn_etalon = \"temp/answers.json\"\n",
    "    log_step = 0\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        super().on_log(args, state, control, logs=logs, **kwargs)\n",
    "        #print(\"kwargs\", len(kwargs), kwargs.keys())\n",
    "        if self.tb_writer is not None:\n",
    "            #print(state)\n",
    "            #print(state.global_step)\n",
    "            #print(self.log_step)\n",
    "            if (self.log_step % self.log_bleu_steps_factor ==0):\n",
    "                model = kwargs['model']\n",
    "                tokenizer = kwargs['tokenizer']\n",
    "                \n",
    "                model.eval()\n",
    "                assert not model.training\n",
    "                generation_config = GenerationConfig(max_new_tokens = self.bleu_generation_max_new_tokens,\n",
    "                                                     # min_new_tokens = 5,\n",
    "                                                     temperature = 1.0\n",
    "                                                    )\n",
    "                print(\"generation_config:\", generation_config)\n",
    "                evaluator = EvaluateTestSet(generation_config = generation_config,\n",
    "                                            fn_test_data = self.bleu_fn_test_data,\n",
    "                                            fn_etalon = self.bleu_fn_etalon,\n",
    "                                            batch_size = 1\n",
    "                                       )\n",
    "\n",
    "                metric_res = evaluator.evaluate(model=model, \n",
    "                                                tokenizer=tokenizer,\n",
    "                                               )\n",
    "                model.train()\n",
    "                assert model.training\n",
    "                print(metric_res)\n",
    "                for key, val in metric_res.items():\n",
    "                    self.tb_writer.add_scalar(key, val, state.global_step)\n",
    "                self.tb_writer.flush()\n",
    "            self.log_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a58e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"/root/experiments_config/\"\n",
    "EXPERIMENTS_PATH = \"/root/experiments/\"\n",
    "experiment_name = \"t2c_concode_220428_v15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc88f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_config_path = os.path.join(CONFIG_PATH, experiment_name + \"_config.json\")\n",
    "experiment_config = json.load(open(current_config_path, \"r\"))\n",
    "\n",
    "assert experiment_config['experiment_name'] == experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50bb0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config['resume_from_checkpoint'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dc63c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert experiment_config['experiment_name'] == experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33f52cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_experiment_path = os.path.join(EXPERIMENTS_PATH, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acf204b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/experiments/t2c_concode_220428_v15’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d7a3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(experiment_config, open(current_experiment_path + \\\n",
    "                                  \"/experiment_config.json\", \n",
    "                                  \"w+\"\n",
    "                                 )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e5bab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a86c7c177540ef876b1028de52689e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n",
      "Found cached dataset json (/root/.cache/huggingface/datasets/json/default-7514164041f99238/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f5f6fe776941e880faa0cec4829a69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = init_lora_model_and_tokenizer(default_model = experiment_config[\"default_model\"],\n",
    "                                                 LORA_R = experiment_config[\"LORA_R\"],\n",
    "                                                 LORA_ALPHA = experiment_config[\"LORA_ALPHA\"],\n",
    "                                                 LORA_DROPOUT = experiment_config[\"LORA_DROPOUT\"]\n",
    "                                                )\n",
    "\n",
    "\n",
    "data = load_dataset(\"json\", \n",
    "                    data_files = experiment_config[\"fn_train_dataset\"]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e83f74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_val = LLaMATokenizer.from_pretrained(\n",
    "    experiment_config['default_model'], add_eos_token=True\n",
    ")\n",
    "tokenizer_val.pad_token_id = 0  # unk. we want this to be different from the eos token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce5420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1527' max='100000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  1527/100000 2:31:38 < 163:11:27, 0.17 it/s, Epoch 0.15/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.613500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.483500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.483700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.270800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.976700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.720400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.429300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.148700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.094000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.099100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.107800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.067200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>1.087900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>1.069500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.070500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>1.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>1.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.950300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>1.061800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.053600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.049200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.040700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.953600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.062200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.988300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.920400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.995400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.990500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.970600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.027300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.945400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.988800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.990600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.019200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.982300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.992700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.929600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.963300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.936200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.951100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.951600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.945800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.994400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.050100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.977800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.960600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.959200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.954100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.955200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.946600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.989400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.989900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.938900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.991200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.928800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.872300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.968600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.977200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.950500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.945900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.908000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.952800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.932100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.941500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.953800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.915400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.921700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.910500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.941700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.959600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.972900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.986900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.980200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.895400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.989300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.938000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.948100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.987200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.950600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.925900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.967600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.946900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.978900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.874300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.959200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.925900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.986700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.930800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.888200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.980500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>1.046500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>1.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.932300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.938900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.956900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>1.040300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>1.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>1.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.961500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>0.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.982600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>0.907500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.981200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>0.940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.941400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>0.985500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>1.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.932500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>0.958100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.931600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>0.868900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.993300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>0.880500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.987600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.68s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 151055.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.0024600119887078407, 'brevity_penalty': 0.3148456301731428, 'ratio': 0.4638922888616891, 'translation_length': 379, 'reference_length': 817, 'precisions_0': 0.060526315789473685, 'precisions_1': 0.005714285714285714, 'precisions_2': 0.003125, 'precisions_3': 0.0034482758620689655}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.70s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 47934.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.0006845063762690473, 'brevity_penalty': 0.0394326698693056, 'ratio': 0.23623011015911874, 'translation_length': 193, 'reference_length': 817, 'precisions_0': 0.13402061855670103, 'precisions_1': 0.012195121951219513, 'precisions_2': 0.006944444444444444, 'precisions_3': 0.008}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.50s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 183157.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.10538026203117587, 'brevity_penalty': 0.7629166207236144, 'ratio': 0.7870257037943696, 'translation_length': 643, 'reference_length': 817, 'precisions_0': 0.4083850931677019, 'precisions_1': 0.20195439739413681, 'precisions_2': 0.08732876712328767, 'precisions_3': 0.05054151624548736}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:41<00:00,  3.40s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 174037.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.15738776043875718, 'brevity_penalty': 0.7043969564488547, 'ratio': 0.7405140758873929, 'translation_length': 605, 'reference_length': 817, 'precisions_0': 0.45544554455445546, 'precisions_1': 0.2847222222222222, 'precisions_2': 0.17399267399267399, 'precisions_3': 0.11046511627906977}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:42<00:00,  3.41s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 184771.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.17177389135814447, 'brevity_penalty': 0.6965145006510369, 'ratio': 0.7343941248470012, 'translation_length': 600, 'reference_length': 817, 'precisions_0': 0.480865224625624, 'precisions_1': 0.3134851138353765, 'precisions_2': 0.19593345656192238, 'precisions_3': 0.12524461839530332}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.44s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 185042.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.12626092972501152, 'brevity_penalty': 0.6580971081453522, 'ratio': 0.7050183598531212, 'translation_length': 576, 'reference_length': 817, 'precisions_0': 0.41074523396880414, 'precisions_1': 0.2522851919561243, 'precisions_2': 0.138996138996139, 'precisions_3': 0.09406952965235174}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.47s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 50311.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.10266264096813267, 'brevity_penalty': 0.7091061824373984, 'ratio': 0.7441860465116279, 'translation_length': 608, 'reference_length': 817, 'precisions_0': 0.34318555008210183, 'precisions_1': 0.18998272884283246, 'precisions_2': 0.1092896174863388, 'precisions_3': 0.06165703275529865}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.47s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 183692.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.16508638980848195, 'brevity_penalty': 0.6917648365258773, 'ratio': 0.7307221542227662, 'translation_length': 597, 'reference_length': 817, 'precisions_0': 0.4682274247491639, 'precisions_1': 0.2975352112676056, 'precisions_2': 0.18773234200743494, 'precisions_3': 0.12401574803149606}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.45s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 173318.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1630713712133514, 'brevity_penalty': 0.7508013522231285, 'ratio': 0.7772337821297429, 'translation_length': 635, 'reference_length': 817, 'precisions_0': 0.4606918238993711, 'precisions_1': 0.2739273927392739, 'precisions_2': 0.16319444444444445, 'precisions_3': 0.10805860805860806}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.46s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 157286.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1740428790016891, 'brevity_penalty': 0.6499738697156315, 'ratio': 0.6988984088127295, 'translation_length': 571, 'reference_length': 817, 'precisions_0': 0.479020979020979, 'precisions_1': 0.3210332103321033, 'precisions_2': 0.21484375, 'precisions_3': 0.15560165975103735}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.46s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 151967.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18531226547952973, 'brevity_penalty': 0.7075381305279058, 'ratio': 0.7429620563035496, 'translation_length': 607, 'reference_length': 817, 'precisions_0': 0.46381578947368424, 'precisions_1': 0.3027681660899654, 'precisions_2': 0.2116788321167883, 'precisions_3': 0.1583011583011583}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.46s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 120873.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.13053037628651365, 'brevity_penalty': 0.6368924160294538, 'ratio': 0.6891064871481029, 'translation_length': 563, 'reference_length': 817, 'precisions_0': 0.4574468085106383, 'precisions_1': 0.26591760299625467, 'precisions_2': 0.1527777777777778, 'precisions_3': 0.0949367088607595}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.52s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 165782.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1397944158620256, 'brevity_penalty': 0.7231424075957652, 'ratio': 0.7552019583843329, 'translation_length': 617, 'reference_length': 817, 'precisions_0': 0.3883495145631068, 'precisions_1': 0.23639455782312926, 'precisions_2': 0.14874551971326164, 'precisions_3': 0.10227272727272728}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.51s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 42581.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1057623179210783, 'brevity_penalty': 0.6253620853529512, 'ratio': 0.6805385556915544, 'translation_length': 556, 'reference_length': 817, 'precisions_0': 0.40574506283662476, 'precisions_1': 0.20872865275142316, 'precisions_2': 0.11871227364185111, 'precisions_3': 0.08137044967880086}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.49s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 172605.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.10092557498745479, 'brevity_penalty': 0.5869397994961546, 'ratio': 0.6523867809057528, 'translation_length': 533, 'reference_length': 817, 'precisions_0': 0.4307116104868914, 'precisions_1': 0.23015873015873015, 'precisions_2': 0.12236286919831224, 'precisions_3': 0.07207207207207207}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.51s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 52276.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.12208961191943266, 'brevity_penalty': 0.6154173979975659, 'ratio': 0.6731946144430845, 'translation_length': 550, 'reference_length': 817, 'precisions_0': 0.4246823956442831, 'precisions_1': 0.255278310940499, 'precisions_2': 0.15682281059063136, 'precisions_3': 0.0911062906724512}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.53s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 166882.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.07565258395239079, 'brevity_penalty': 0.49555182798627206, 'ratio': 0.587515299877601, 'translation_length': 480, 'reference_length': 817, 'precisions_0': 0.39293139293139295, 'precisions_1': 0.21507760532150777, 'precisions_2': 0.10926365795724466, 'precisions_3': 0.058823529411764705}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.52s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 167325.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1292215978498019, 'brevity_penalty': 0.5970407294744448, 'ratio': 0.6597307221542228, 'translation_length': 539, 'reference_length': 817, 'precisions_0': 0.4388888888888889, 'precisions_1': 0.2647058823529412, 'precisions_2': 0.16666666666666666, 'precisions_3': 0.11333333333333333}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.48s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 178734.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18046711875981433, 'brevity_penalty': 0.6483443410015097, 'ratio': 0.6976744186046512, 'translation_length': 570, 'reference_length': 817, 'precisions_0': 0.5481611208406305, 'precisions_1': 0.34935304990757854, 'precisions_2': 0.22265625, 'precisions_3': 0.14078674948240166}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.47s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 181833.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1546121005342285, 'brevity_penalty': 0.7385767149187981, 'ratio': 0.7674418604651163, 'translation_length': 627, 'reference_length': 817, 'precisions_0': 0.4442675159235669, 'precisions_1': 0.26588628762541805, 'precisions_2': 0.1619718309859155, 'precisions_3': 0.10037174721189591}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.50s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 176478.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1806566702525487, 'brevity_penalty': 0.6467131914862885, 'ratio': 0.6964504283965728, 'translation_length': 569, 'reference_length': 817, 'precisions_0': 0.5, 'precisions_1': 0.31851851851851853, 'precisions_2': 0.22941176470588234, 'precisions_3': 0.16666666666666666}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.49s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 178734.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.17176456321917413, 'brevity_penalty': 0.7308808538462902, 'ratio': 0.7613219094247246, 'translation_length': 622, 'reference_length': 817, 'precisions_0': 0.48635634028892455, 'precisions_1': 0.2866779089376054, 'precisions_2': 0.17939609236234458, 'precisions_3': 0.12195121951219512}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.49s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 163626.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1640386916817294, 'brevity_penalty': 0.6613349669059593, 'ratio': 0.7074663402692778, 'translation_length': 578, 'reference_length': 817, 'precisions_0': 0.5008635578583766, 'precisions_1': 0.29508196721311475, 'precisions_2': 0.1926782273603083, 'precisions_3': 0.1329243353783231}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.49s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 171897.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.13030392114079886, 'brevity_penalty': 0.5987189659716076, 'ratio': 0.6609547123623011, 'translation_length': 540, 'reference_length': 817, 'precisions_0': 0.44731977818853974, 'precisions_1': 0.2583170254403131, 'precisions_2': 0.1683991683991684, 'precisions_3': 0.11529933481152993}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.46s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 43166.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.12417288696061038, 'brevity_penalty': 0.6949329590747322, 'ratio': 0.7331701346389229, 'translation_length': 599, 'reference_length': 817, 'precisions_0': 0.37333333333333335, 'precisions_1': 0.22280701754385965, 'precisions_2': 0.1388888888888889, 'precisions_3': 0.08823529411764706}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.49s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 172842.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.19755287571657262, 'brevity_penalty': 0.7215896154822341, 'ratio': 0.7539779681762546, 'translation_length': 616, 'reference_length': 817, 'precisions_0': 0.5072933549432739, 'precisions_1': 0.32367972742759793, 'precisions_2': 0.21723518850987433, 'precisions_3': 0.15749525616698293}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.48s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 44874.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.16324088569985223, 'brevity_penalty': 0.6774254411055589, 'ratio': 0.7197062423500612, 'translation_length': 588, 'reference_length': 817, 'precisions_0': 0.5144312393887945, 'precisions_1': 0.3023255813953488, 'precisions_2': 0.1833648393194707, 'precisions_3': 0.11823647294589178}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.46s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 190361.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.16176557161686123, 'brevity_penalty': 0.6336059892857467, 'ratio': 0.6866585067319462, 'translation_length': 561, 'reference_length': 817, 'precisions_0': 0.49466192170818507, 'precisions_1': 0.3007518796992481, 'precisions_2': 0.20119521912350596, 'precisions_3': 0.1419491525423729}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.45s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 60349.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1544262260553553, 'brevity_penalty': 0.7012490298260343, 'ratio': 0.7380660954712362, 'translation_length': 603, 'reference_length': 817, 'precisions_0': 0.4586092715231788, 'precisions_1': 0.2613240418118467, 'precisions_2': 0.17095588235294118, 'precisions_3': 0.11478599221789883}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.47s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 56324.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.17111245701962988, 'brevity_penalty': 0.6774254411055589, 'ratio': 0.7197062423500612, 'translation_length': 588, 'reference_length': 817, 'precisions_0': 0.5178268251273345, 'precisions_1': 0.3023255813953488, 'precisions_2': 0.19659735349716445, 'precisions_3': 0.13226452905811623}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.53s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 172368.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.12821398419938143, 'brevity_penalty': 0.6901782584838726, 'ratio': 0.7294981640146879, 'translation_length': 596, 'reference_length': 817, 'precisions_0': 0.4556113902847571, 'precisions_1': 0.2345679012345679, 'precisions_2': 0.1378026070763501, 'precisions_3': 0.08086785009861933}\n"
     ]
    }
   ],
   "source": [
    "def generate_prompt(data_point):\n",
    "    # sorry about the formatting disaster gotta move fast\n",
    "    if data_point[\"input\"]:\n",
    "        return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "### Input:\n",
    "{data_point[\"input\"]}\n",
    "### Response:\n",
    "{data_point[\"output\"]}\"\"\"\n",
    "    else:\n",
    "        return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{data_point[\"instruction\"]}\n",
    "### Response:\n",
    "{data_point[\"output\"]}\"\"\"\n",
    "\n",
    "\n",
    "data = data.shuffle().map(\n",
    "    lambda data_point: tokenizer(\n",
    "        generate_prompt(data_point),\n",
    "        truncation=experiment_config[\"truncation\"],\n",
    "        max_length=experiment_config[\"CUTOFF_LEN\"],\n",
    "        padding=experiment_config[\"padding\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer_val,\n",
    "    train_dataset=data[\"train\"],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=experiment_config[\"MICRO_BATCH_SIZE\"],\n",
    "        gradient_accumulation_steps=experiment_config[\"GRADIENT_ACCUMULATION_STEPS\"],\n",
    "        warmup_steps=experiment_config[\"warmup_steps\"],\n",
    "        num_train_epochs=experiment_config[\"EPOCHS\"],\n",
    "        learning_rate=experiment_config[\"LEARNING_RATE\"],\n",
    "        fp16=experiment_config[\"fp16\"],\n",
    "        logging_steps=experiment_config[\"logging_steps\"],\n",
    "        output_dir=current_experiment_path,#\"lora-alpaca\",\n",
    "        save_total_limit=experiment_config[\"save_total_limit\"],\n",
    "        save_strategy = experiment_config[\"save_strategy\"],\n",
    "        save_steps = experiment_config[\"save_steps\"],\n",
    "        seed=experiment_config[\"seed\"],\n",
    "        logging_dir=current_experiment_path,\n",
    "        logging_strategy=experiment_config[\"logging_strategy\"],\n",
    "        report_to=experiment_config[\"report_to\"]\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, \n",
    "                                                               mlm=experiment_config[\"mlm\"]\n",
    "                                                              ),\n",
    "    callbacks = [MyCustomCallback]\n",
    ")\n",
    "model.config.use_cache = experiment_config[\"config_use_cache\"]\n",
    "# print(len(trainer.optimizer.state['found_inf_per_device']))\n",
    "\n",
    "\n",
    "trainer.train(resume_from_checkpoint=experiment_config[\"resume_from_checkpoint\"])\n",
    "\n",
    "model.save_pretrained(current_experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "665c1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(current_experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e72383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay          45G   37G  8.4G  82% /\r\n"
     ]
    }
   ],
   "source": [
    "!df -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62ecf14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment_config[\"resume_from_checkpoint\"]\n",
    "GenerationConfig(max_new_tokens = 15,\n",
    "                 #min_new_tokens = 5,\n",
    "                 temperature = 1.0\n",
    "                ).temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateTestSet()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
