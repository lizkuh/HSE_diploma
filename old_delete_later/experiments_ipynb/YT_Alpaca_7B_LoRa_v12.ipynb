{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ac0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All to folder\n",
    "## generate prompt\n",
    "# !ls data\n",
    "# import time\n",
    "# time.sleep(60*30)\n",
    "\n",
    "# Try to do:\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c4ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import transformers\n",
    "from peft import PeftModel\n",
    "from transformers import LlamaForCausalLM as LLaMAForCausalLM\n",
    "from transformers import LlamaTokenizer as LLaMATokenizer\n",
    "from peft import prepare_model_for_int8_training, LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "from EvaluateTestSet import EvaluateTestSet\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "def init_lora_model_and_tokenizer(default_model,\n",
    "                             LORA_R,\n",
    "                             LORA_ALPHA,\n",
    "                             LORA_DROPOUT\n",
    "                            ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    model = LLaMAForCausalLM.from_pretrained(\n",
    "    default_model,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    )\n",
    "    tokenizer = LLaMATokenizer.from_pretrained(\n",
    "        default_model, add_eos_token=True\n",
    "    )\n",
    "\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=LORA_R,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    tokenizer.pad_token_id = 0  # unk. we want this to be different from the eos token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "class MyCustomCallback(TensorBoardCallback):\n",
    "    #log_bleu_steps_factor = 5\n",
    "    bleu_generation_max_new_tokens = 30\n",
    "    bleu_fn_test_data = \"temp/t2c_answers.json\"\n",
    "    bleu_fn_etalon = \"temp/answers.json\"\n",
    "    log_step = 0\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        super().on_log(args, state, control, logs=logs, **kwargs)\n",
    "        #print(\"kwargs\", len(kwargs), kwargs.keys())\n",
    "        if self.tb_writer is not None:\n",
    "            #print(state)\n",
    "            #print(state.global_step)\n",
    "            #print(self.log_step)\n",
    "            if (self.log_step % self.log_bleu_steps_factor ==0):\n",
    "                model = kwargs['model']\n",
    "                tokenizer = kwargs['tokenizer']\n",
    "                \n",
    "                model.eval()\n",
    "                assert not model.training\n",
    "                generation_config = GenerationConfig(max_new_tokens = self.bleu_generation_max_new_tokens,\n",
    "                                                     # min_new_tokens = 5,\n",
    "                                                     temperature = 1.0\n",
    "                                                    )\n",
    "                print(\"generation_config:\", generation_config)\n",
    "                evaluator = EvaluateTestSet(generation_config = generation_config,\n",
    "                                            fn_test_data = self.bleu_fn_test_data,\n",
    "                                            fn_etalon = self.bleu_fn_etalon,\n",
    "                                            batch_size = 1\n",
    "                                       )\n",
    "\n",
    "                metric_res = evaluator.evaluate(model=model, \n",
    "                                                tokenizer=tokenizer,\n",
    "                                               )\n",
    "                model.train()\n",
    "                assert model.training\n",
    "                print(metric_res)\n",
    "                for key, val in metric_res.items():\n",
    "                    #add \"custom/something\"\n",
    "                    self.tb_writer.add_scalar(key, val, state.global_step)\n",
    "                self.tb_writer.flush()\n",
    "            self.log_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a58e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"/root/experiments_configs/\"\n",
    "EXPERIMENTS_PATH = \"/root/experiments/\"\n",
    "experiment_name = \"t2c_concode_220428_v20\"\n",
    "# t2c_concode_220428_v18.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37a72cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2c_concode_220428_v14_config.json  t2c_concode_220428_v18_config.json\r\n",
      "t2c_concode_220428_v15_config.json  t2c_concode_220428_v19_config.json\r\n",
      "t2c_concode_220428_v16_config.json  t2c_concode_220428_v20_config.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls /root/experiments_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc88f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_config_path = os.path.join(CONFIG_PATH, experiment_name + \"_config.json\")\n",
    "experiment_config = json.load(open(current_config_path, \"r\"))\n",
    "\n",
    "assert experiment_config['experiment_name'] == experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eff1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config['resume_from_checkpoint'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50bb0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert experiment_config['resume_from_checkpoint'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dc63c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert experiment_config['experiment_name'] == experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33f52cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_experiment_path = os.path.join(EXPERIMENTS_PATH, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acf204b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/experiments/t2c_concode_220428_v20’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d7a3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(experiment_config, open(current_experiment_path + \\\n",
    "                                  \"/experiment_config.json\", \n",
    "                                  \"w+\"\n",
    "                                 )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "946d5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(MyCustomCallback, \"log_bleu_steps_factor\", experiment_config['log_bleu_steps_factor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63e33b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyCustomCallback.log_bleu_steps_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e5bab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b38d48913c4261826a824e93f0b6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n",
      "Found cached dataset json (/root/.cache/huggingface/datasets/json/default-3ac2744fedc77f2f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728ac68f36944f68ae66b94decfd669e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = init_lora_model_and_tokenizer(default_model = experiment_config[\"default_model\"],\n",
    "                                                 LORA_R = experiment_config[\"LORA_R\"],\n",
    "                                                 LORA_ALPHA = experiment_config[\"LORA_ALPHA\"],\n",
    "                                                 LORA_DROPOUT = experiment_config[\"LORA_DROPOUT\"]\n",
    "                                                )\n",
    "\n",
    "\n",
    "data = load_dataset(\"json\", \n",
    "                    data_files = {\"train\": experiment_config[\"fn_train_dataset\"],\n",
    "                                  \"eval\":  experiment_config[\"fn_eval_dataset\"]\n",
    "                                 }\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e83f74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_val = LLaMATokenizer.from_pretrained(\n",
    "    experiment_config['default_model'], add_eos_token=True\n",
    ")\n",
    "tokenizer_val.pad_token_id = 0  # unk. we want this to be different from the eos token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a58aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config[\"logging_steps\"] = 1\n",
    "# experiment_config[\"eval_steps\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "415d4e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 't2c_concode_220428_v20',\n",
       " 'fn_train_dataset': '/root/data/t2c_train.json',\n",
       " 'fn_eval_dataset': '/root/data/t2c_answers.json',\n",
       " 'default_model': 'decapoda-research/llama-7b-hf',\n",
       " 'MICRO_BATCH_SIZE': 2,\n",
       " 'BATCH_SIZE': 10,\n",
       " 'EPOCHS': 2,\n",
       " 'LEARNING_RATE': 0.0002,\n",
       " 'CUTOFF_LEN': 256,\n",
       " 'LORA_R': 64,\n",
       " 'LORA_ALPHA': 16,\n",
       " 'LORA_DROPOUT': 0.05,\n",
       " 'warmup_steps': 200,\n",
       " 'fp16': True,\n",
       " 'logging_steps': 10,\n",
       " 'eval_steps': 100,\n",
       " 'evaluation_strategy': 'steps',\n",
       " 'save_total_limit': 1,\n",
       " 'save_strategy': 'steps',\n",
       " 'save_steps': 500,\n",
       " 'seed': 42,\n",
       " 'logging_strategy': 'steps',\n",
       " 'report_to': 'tensorboard',\n",
       " 'mlm': False,\n",
       " 'truncation': True,\n",
       " 'padding': 'max_length',\n",
       " 'config_use_cache': False,\n",
       " 'resume_from_checkpoint': True,\n",
       " 'bleu_batch_size': 5,\n",
       " 'GRADIENT_ACCUMULATION_STEPS': 5,\n",
       " 'log_bleu_steps_factor': 50}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_config\n",
    "# {'experiment_name': 't2c_concode_220428_v19',\n",
    "#  'fn_train_dataset': '/root/data/t2c_train.json',\n",
    "#  'fn_eval_dataset': '/root/data/t2c_answers.json',\n",
    "#  'default_model': 'decapoda-research/llama-7b-hf',\n",
    "#  'MICRO_BATCH_SIZE': 2,\n",
    "#  'BATCH_SIZE': 10,\n",
    "#  'EPOCHS': 2,\n",
    "#  'LEARNING_RATE': 0.0002,\n",
    "#  'CUTOFF_LEN': 256,\n",
    "#  'LORA_R': 16,\n",
    "#  'LORA_ALPHA': 16,\n",
    "#  'LORA_DROPOUT': 0.05,\n",
    "#  'warmup_steps': 200,\n",
    "#  'fp16': True,\n",
    "#  'logging_steps': 10,\n",
    "#  'eval_steps': 100,\n",
    "#  'evaluation_strategy': 'steps',\n",
    "#  'save_total_limit': 1,\n",
    "#  'save_strategy': 'steps',\n",
    "#  'save_steps': 500,\n",
    "#  'seed': 42,\n",
    "#  'logging_strategy': 'steps',\n",
    "#  'report_to': 'tensorboard',\n",
    "#  'mlm': False,\n",
    "#  'truncation': True,\n",
    "#  'padding': 'max_length',\n",
    "#  'config_use_cache': False,\n",
    "#  'resume_from_checkpoint': False,\n",
    "#  'bleu_batch_size': 5,\n",
    "#  'GRADIENT_ACCUMULATION_STEPS': 5,\n",
    "#  'log_bleu_steps_factor': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6708fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config[\"resume_from_checkpoint\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1229c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ipynb/prompter/templates/\n"
     ]
    }
   ],
   "source": [
    "from prompter import Prompter\n",
    "prompter = Prompter()\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    if \"input\" in data_point and data_point[\"input\"]:\n",
    "        return prompter.generate_prompt(instruction = data_point[\"instruction\"],\n",
    "                                        input = data_point[\"input\"],\n",
    "                                        label = data_point[\"output\"]\n",
    "                                       )\n",
    "    else:\n",
    "        return prompter.generate_prompt(instruction = data_point[\"instruction\"],\n",
    "                                        #input = None,\n",
    "                                        label = data_point[\"output\"]\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bc4af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config[\"resume_from_checkpoint\"] ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5dce5420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20000/20000 11:03:21, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>1.087022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.810300</td>\n",
       "      <td>1.085437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.755500</td>\n",
       "      <td>1.088016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.788800</td>\n",
       "      <td>1.088612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.727600</td>\n",
       "      <td>1.088346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.844300</td>\n",
       "      <td>1.086932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.708300</td>\n",
       "      <td>1.089077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.720900</td>\n",
       "      <td>1.087213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.726200</td>\n",
       "      <td>1.087835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.811500</td>\n",
       "      <td>1.087993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.816600</td>\n",
       "      <td>1.086133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>1.086114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.703600</td>\n",
       "      <td>1.092349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>1.088775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.768600</td>\n",
       "      <td>1.087521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>1.086932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>1.084062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.807600</td>\n",
       "      <td>1.082862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.802800</td>\n",
       "      <td>1.086913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.768400</td>\n",
       "      <td>1.086580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.758400</td>\n",
       "      <td>1.088660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.800200</td>\n",
       "      <td>1.082036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.724800</td>\n",
       "      <td>1.082429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>1.083921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.728500</td>\n",
       "      <td>1.084217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13100</td>\n",
       "      <td>0.683600</td>\n",
       "      <td>1.084215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.719700</td>\n",
       "      <td>1.088926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>0.769300</td>\n",
       "      <td>1.085247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.747100</td>\n",
       "      <td>1.081557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.696400</td>\n",
       "      <td>1.084913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.685700</td>\n",
       "      <td>1.085786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13700</td>\n",
       "      <td>0.708500</td>\n",
       "      <td>1.085236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.704000</td>\n",
       "      <td>1.083788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13900</td>\n",
       "      <td>0.749500</td>\n",
       "      <td>1.083821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.744700</td>\n",
       "      <td>1.085290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14100</td>\n",
       "      <td>0.759200</td>\n",
       "      <td>1.082230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.750900</td>\n",
       "      <td>1.082857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14300</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>1.087132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.807700</td>\n",
       "      <td>1.083942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.721500</td>\n",
       "      <td>1.084579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.082577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14700</td>\n",
       "      <td>0.727200</td>\n",
       "      <td>1.083770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>1.082976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14900</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>1.082710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.789300</td>\n",
       "      <td>1.081211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15100</td>\n",
       "      <td>0.730200</td>\n",
       "      <td>1.081484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.720200</td>\n",
       "      <td>1.081357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15300</td>\n",
       "      <td>0.711400</td>\n",
       "      <td>1.084836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.747400</td>\n",
       "      <td>1.083544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.799100</td>\n",
       "      <td>1.081740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.732100</td>\n",
       "      <td>1.082324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15700</td>\n",
       "      <td>0.729000</td>\n",
       "      <td>1.082898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>0.745300</td>\n",
       "      <td>1.083128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15900</td>\n",
       "      <td>0.762800</td>\n",
       "      <td>1.082160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.080853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16100</td>\n",
       "      <td>0.750200</td>\n",
       "      <td>1.083502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>0.735200</td>\n",
       "      <td>1.081936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16300</td>\n",
       "      <td>0.769700</td>\n",
       "      <td>1.082481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>0.790900</td>\n",
       "      <td>1.082728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.704700</td>\n",
       "      <td>1.083055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>0.705400</td>\n",
       "      <td>1.081592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16700</td>\n",
       "      <td>0.766700</td>\n",
       "      <td>1.082430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.686100</td>\n",
       "      <td>1.080753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16900</td>\n",
       "      <td>0.779100</td>\n",
       "      <td>1.082548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.813900</td>\n",
       "      <td>1.079658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17100</td>\n",
       "      <td>0.699100</td>\n",
       "      <td>1.082321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>0.757300</td>\n",
       "      <td>1.081821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17300</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>1.084332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>0.718600</td>\n",
       "      <td>1.081723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.741300</td>\n",
       "      <td>1.081289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>0.751100</td>\n",
       "      <td>1.080949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17700</td>\n",
       "      <td>0.741400</td>\n",
       "      <td>1.080684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17800</td>\n",
       "      <td>0.736400</td>\n",
       "      <td>1.082065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17900</td>\n",
       "      <td>0.712200</td>\n",
       "      <td>1.083995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.724800</td>\n",
       "      <td>1.080120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18100</td>\n",
       "      <td>0.685800</td>\n",
       "      <td>1.080560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18200</td>\n",
       "      <td>0.740800</td>\n",
       "      <td>1.082470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18300</td>\n",
       "      <td>0.800400</td>\n",
       "      <td>1.081540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18400</td>\n",
       "      <td>0.743500</td>\n",
       "      <td>1.080767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.700700</td>\n",
       "      <td>1.080671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18600</td>\n",
       "      <td>0.761800</td>\n",
       "      <td>1.081233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18700</td>\n",
       "      <td>0.702100</td>\n",
       "      <td>1.081476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18800</td>\n",
       "      <td>0.746800</td>\n",
       "      <td>1.080336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18900</td>\n",
       "      <td>0.845700</td>\n",
       "      <td>1.080539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.707500</td>\n",
       "      <td>1.081059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19100</td>\n",
       "      <td>0.764600</td>\n",
       "      <td>1.079314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>0.743600</td>\n",
       "      <td>1.080942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19300</td>\n",
       "      <td>0.727100</td>\n",
       "      <td>1.080844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19400</td>\n",
       "      <td>0.777900</td>\n",
       "      <td>1.079756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.758800</td>\n",
       "      <td>1.080703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19600</td>\n",
       "      <td>0.672900</td>\n",
       "      <td>1.080732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19700</td>\n",
       "      <td>0.758100</td>\n",
       "      <td>1.080110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19800</td>\n",
       "      <td>0.735800</td>\n",
       "      <td>1.079630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19900</td>\n",
       "      <td>0.672100</td>\n",
       "      <td>1.079935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.804300</td>\n",
       "      <td>1.080995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 50371.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18738615970220884, 'brevity_penalty': 0.6303131865967199, 'ratio': 0.6842105263157895, 'translation_length': 559, 'reference_length': 817, 'precisions_0': 0.5875, 'precisions_1': 0.37735849056603776, 'precisions_2': 0.23, 'precisions_3': 0.15319148936170213}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.55s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 167325.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18938180012882233, 'brevity_penalty': 0.6933497372178419, 'ratio': 0.7319461444308446, 'translation_length': 598, 'reference_length': 817, 'precisions_0': 0.5575959933222037, 'precisions_1': 0.3462214411247803, 'precisions_2': 0.20964749536178107, 'precisions_3': 0.137524557956778}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.55s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 165347.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1925897484503871, 'brevity_penalty': 0.6885900046167743, 'ratio': 0.7282741738066095, 'translation_length': 595, 'reference_length': 817, 'precisions_0': 0.5536912751677853, 'precisions_1': 0.34452296819787986, 'precisions_2': 0.21641791044776118, 'precisions_3': 0.1482213438735178}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.54s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 165564.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.190964746949918, 'brevity_penalty': 0.6677909732374923, 'ratio': 0.7123623011015912, 'translation_length': 582, 'reference_length': 817, 'precisions_0': 0.5591766723842195, 'precisions_1': 0.35443037974683544, 'precisions_2': 0.22179732313575526, 'precisions_3': 0.15212981744421908}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.57s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 152335.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18094466097927478, 'brevity_penalty': 0.6418100460327502, 'ratio': 0.6927784577723378, 'translation_length': 566, 'reference_length': 817, 'precisions_0': 0.5731922398589065, 'precisions_1': 0.3649906890130354, 'precisions_2': 0.21499013806706113, 'precisions_3': 0.14046121593291405}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 162991.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20651460142051795, 'brevity_penalty': 0.6933497372178419, 'ratio': 0.7319461444308446, 'translation_length': 598, 'reference_length': 817, 'precisions_0': 0.5759599332220368, 'precisions_1': 0.37258347978910367, 'precisions_2': 0.23933209647495363, 'precisions_3': 0.15324165029469547}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.69s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 41748.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2067651461769529, 'brevity_penalty': 0.687000076489837, 'ratio': 0.7270501835985312, 'translation_length': 594, 'reference_length': 817, 'precisions_0': 0.5815126050420169, 'precisions_1': 0.3769911504424779, 'precisions_2': 0.23925233644859814, 'precisions_3': 0.15643564356435644}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.69s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 171196.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21235904391476906, 'brevity_penalty': 0.6774254411055589, 'ratio': 0.7197062423500612, 'translation_length': 588, 'reference_length': 817, 'precisions_0': 0.5738539898132428, 'precisions_1': 0.3810375670840787, 'precisions_2': 0.2533081285444234, 'precisions_3': 0.1743486973947896}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.68s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 153450.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20331335110686685, 'brevity_penalty': 0.6806236541219175, 'ratio': 0.7221542227662179, 'translation_length': 590, 'reference_length': 817, 'precisions_0': 0.5803722504230119, 'precisions_1': 0.37433155080213903, 'precisions_2': 0.23540489642184556, 'precisions_3': 0.15568862275449102}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:51<00:00,  3.70s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 170039.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18846687992286243, 'brevity_penalty': 0.6694008551670413, 'ratio': 0.7135862913096696, 'translation_length': 583, 'reference_length': 817, 'precisions_0': 0.5513698630136986, 'precisions_1': 0.35018050541516244, 'precisions_2': 0.22328244274809161, 'precisions_3': 0.145748987854251}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:51<00:00,  3.73s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 52582.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.19123331388467507, 'brevity_penalty': 0.6806236541219175, 'ratio': 0.7221542227662179, 'translation_length': 590, 'reference_length': 817, 'precisions_0': 0.5769881556683587, 'precisions_1': 0.3600713012477718, 'precisions_2': 0.21468926553672316, 'precisions_3': 0.13972055888223553}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.69s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 54166.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18972670573838293, 'brevity_penalty': 0.7091061824373984, 'ratio': 0.7441860465116279, 'translation_length': 608, 'reference_length': 817, 'precisions_0': 0.5385878489326765, 'precisions_1': 0.33678756476683935, 'precisions_2': 0.20947176684881602, 'precisions_3': 0.1348747591522158}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.70s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 153263.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20513354067885775, 'brevity_penalty': 0.6726156603918537, 'ratio': 0.7160342717258262, 'translation_length': 585, 'reference_length': 817, 'precisions_0': 0.5921501706484642, 'precisions_1': 0.37949640287769787, 'precisions_2': 0.23574144486692014, 'precisions_3': 0.16330645161290322}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:51<00:00,  3.73s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 162991.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20069603932815194, 'brevity_penalty': 0.6629514358413311, 'ratio': 0.7086903304773562, 'translation_length': 579, 'reference_length': 817, 'precisions_0': 0.5879310344827586, 'precisions_1': 0.3781818181818182, 'precisions_2': 0.2403846153846154, 'precisions_3': 0.15714285714285714}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:51<00:00,  3.72s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 52276.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1981926659866338, 'brevity_penalty': 0.6450804239336081, 'ratio': 0.6952264381884945, 'translation_length': 568, 'reference_length': 817, 'precisions_0': 0.5729349736379613, 'precisions_1': 0.37291280148423006, 'precisions_2': 0.24361493123772102, 'precisions_3': 0.17118997912317327}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.70s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 161526.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18877106359064635, 'brevity_penalty': 0.6532280539448486, 'ratio': 0.7013463892288861, 'translation_length': 573, 'reference_length': 817, 'precisions_0': 0.5609756097560976, 'precisions_1': 0.3602941176470588, 'precisions_2': 0.22568093385214008, 'precisions_3': 0.15289256198347106}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.67s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 139654.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20616109300705415, 'brevity_penalty': 0.6710090849121607, 'ratio': 0.7148102815177478, 'translation_length': 584, 'reference_length': 817, 'precisions_0': 0.5811965811965812, 'precisions_1': 0.3783783783783784, 'precisions_2': 0.24761904761904763, 'precisions_3': 0.16363636363636364}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.69s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 53453.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1940429019509652, 'brevity_penalty': 0.6980943605403788, 'ratio': 0.7356181150550796, 'translation_length': 601, 'reference_length': 817, 'precisions_0': 0.5697674418604651, 'precisions_1': 0.36013986013986016, 'precisions_2': 0.2158671586715867, 'precisions_3': 0.134765625}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:49<00:00,  3.65s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 167996.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20266631353798664, 'brevity_penalty': 0.6758238404571268, 'ratio': 0.7184822521419829, 'translation_length': 587, 'reference_length': 817, 'precisions_0': 0.5714285714285714, 'precisions_1': 0.36917562724014336, 'precisions_2': 0.23863636363636365, 'precisions_3': 0.1606425702811245}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.70s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 161734.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2046316048698303, 'brevity_penalty': 0.6790253796134038, 'ratio': 0.7209302325581395, 'translation_length': 589, 'reference_length': 817, 'precisions_0': 0.5677966101694916, 'precisions_1': 0.36964285714285716, 'precisions_2': 0.23962264150943396, 'precisions_3': 0.164}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.68s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 51888.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20120282170325496, 'brevity_penalty': 0.7153614637961878, 'ratio': 0.7490820073439413, 'translation_length': 612, 'reference_length': 817, 'precisions_0': 0.564437194127243, 'precisions_1': 0.35334476843910806, 'precisions_2': 0.21880650994575046, 'precisions_3': 0.14340344168260039}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# def generate_prompt(data_point):\n",
    "#     # sorry about the formatting disaster gotta move fast\n",
    "#     if data_point[\"input\"]:\n",
    "#         return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "# ### Instruction:\n",
    "# {data_point[\"instruction\"]}\n",
    "# ### Input:\n",
    "# {data_point[\"input\"]}\n",
    "# ### Response:\n",
    "# {data_point[\"output\"]}\"\"\"\n",
    "#     else:\n",
    "#         return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "# ### Instruction:\n",
    "# {data_point[\"instruction\"]}\n",
    "# ### Response:\n",
    "# {data_point[\"output\"]}\"\"\"\n",
    "\n",
    "\n",
    "data = data.shuffle().map(\n",
    "    lambda data_point: tokenizer(\n",
    "        generate_prompt(data_point),\n",
    "        truncation=experiment_config[\"truncation\"],\n",
    "        max_length=experiment_config[\"CUTOFF_LEN\"],\n",
    "        padding=experiment_config[\"padding\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer_val,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data['eval'],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=experiment_config[\"MICRO_BATCH_SIZE\"],\n",
    "        gradient_accumulation_steps=experiment_config[\"GRADIENT_ACCUMULATION_STEPS\"],\n",
    "        warmup_steps=experiment_config[\"warmup_steps\"],\n",
    "        num_train_epochs=experiment_config[\"EPOCHS\"],\n",
    "        learning_rate=experiment_config[\"LEARNING_RATE\"],\n",
    "        fp16=experiment_config[\"fp16\"],\n",
    "        logging_steps=experiment_config[\"logging_steps\"],        \n",
    "        evaluation_strategy = experiment_config['evaluation_strategy'],\n",
    "        eval_steps=experiment_config[\"eval_steps\"],\n",
    "        output_dir=current_experiment_path,#\"lora-alpaca\",\n",
    "        save_total_limit=experiment_config[\"save_total_limit\"],\n",
    "        save_strategy = experiment_config[\"save_strategy\"],\n",
    "        \n",
    "        save_steps = experiment_config[\"save_steps\"],\n",
    "        seed=experiment_config[\"seed\"],\n",
    "        logging_dir=current_experiment_path,\n",
    "        logging_strategy=experiment_config[\"logging_strategy\"],\n",
    "        report_to=experiment_config[\"report_to\"]\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, \n",
    "                                                               mlm=experiment_config[\"mlm\"]\n",
    "                                                              ),\n",
    "    callbacks = [MyCustomCallback]\n",
    ")\n",
    "model.config.use_cache = experiment_config[\"config_use_cache\"]\n",
    "# print(len(trainer.optimizer.state['found_inf_per_device']))\n",
    "\n",
    "\n",
    "trainer.train(resume_from_checkpoint=experiment_config[\"resume_from_checkpoint\"])\n",
    "\n",
    "model.save_pretrained(current_experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1ced47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls -lah /root/experiments/t2c_concode_220428_v20\n",
    "!ls {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "665c1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(current_experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e72383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8f14bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay          45G   21G   25G  47% /\r\n"
     ]
    }
   ],
   "source": [
    "!df -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "392d638c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 56K\r\n",
      "drwxr-xr-x  6 root root  250 May 10 23:47 .\r\n",
      "drwxr-xr-x 13 root root 4.0K May 10 22:36 ..\r\n",
      "drwxr-xr-x  2 root root   65 May 10 22:38 1683758323.605443\r\n",
      "drwxr-xr-x  2 root root   65 May 10 22:38 1683758323.6125872\r\n",
      "drwxr-xr-x  2 root root   31 May 10 23:47 checkpoint-1000\r\n",
      "drwxr-xr-x  2 root root  243 May 10 23:14 checkpoint-500\r\n",
      "-rw-r--r--  1 root root  22K May 10 23:47 events.out.tfevents.1683758323.8d048d63ed1a.14655.0\r\n",
      "-rw-r--r--  1 root root  24K May 10 23:47 events.out.tfevents.1683758323.8d048d63ed1a.14655.2\r\n",
      "-rw-r--r--  1 root root  794 May 10 22:36 experiment_config.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efcd7e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/experiments/t2c_concode_220428_v20'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_experiment_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d411735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7.0G\r\n",
      "drwxr-xr-x 2 root root  243 May 10 23:14 .\r\n",
      "drwxr-xr-x 6 root root  250 May 10 23:47 ..\r\n",
      "-rw-r--r-- 1 root root 257M May 10 23:14 optimizer.pt\r\n",
      "-rw-r--r-- 1 root root 6.7G May 10 23:14 pytorch_model.bin\r\n",
      "-rw-r--r-- 1 root root  15K May 10 23:14 rng_state.pth\r\n",
      "-rw-r--r-- 1 root root  557 May 10 23:14 scaler.pt\r\n",
      "-rw-r--r-- 1 root root  627 May 10 23:14 scheduler.pt\r\n",
      "-rw-r--r-- 1 root root  423 May 10 23:14 special_tokens_map.json\r\n",
      "-rw-r--r-- 1 root root 489K May 10 23:14 tokenizer.model\r\n",
      "-rw-r--r-- 1 root root  714 May 10 23:14 tokenizer_config.json\r\n",
      "-rw-r--r-- 1 root root 7.1K May 10 23:14 trainer_state.json\r\n",
      "-rw-r--r-- 1 root root 3.5K May 10 23:14 training_args.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah /root/experiments/t2c_concode_220428_v20/checkpoint-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aff2fe16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7.0G\r\n",
      "drwxr-xr-x 2 root root  243 May 10 23:14 .\r\n",
      "drwxr-xr-x 5 root root  227 May 11 07:54 ..\r\n",
      "-rw-r--r-- 1 root root 257M May 10 23:14 optimizer.pt\r\n",
      "-rw-r--r-- 1 root root 6.7G May 10 23:14 pytorch_model.bin\r\n",
      "-rw-r--r-- 1 root root  15K May 10 23:14 rng_state.pth\r\n",
      "-rw-r--r-- 1 root root  557 May 10 23:14 scaler.pt\r\n",
      "-rw-r--r-- 1 root root  627 May 10 23:14 scheduler.pt\r\n",
      "-rw-r--r-- 1 root root  423 May 10 23:14 special_tokens_map.json\r\n",
      "-rw-r--r-- 1 root root 489K May 10 23:14 tokenizer.model\r\n",
      "-rw-r--r-- 1 root root  714 May 10 23:14 tokenizer_config.json\r\n",
      "-rw-r--r-- 1 root root 7.1K May 10 23:14 trainer_state.json\r\n",
      "-rw-r--r-- 1 root root 3.5K May 10 23:14 training_args.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah /root/experiments/t2c_concode_220428_v20/checkpoint-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9dca9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay          45G   32G   14G  71% /\r\n"
     ]
    }
   ],
   "source": [
    "# !rm -rf /root/experiments/t2c_concode_220428_v19/checkpoint-20000/\n",
    "# !df -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97279e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf {current_experiment_path}/checkpoint-1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feedd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731023f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
