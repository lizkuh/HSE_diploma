{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ac0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All to folder\n",
    "## generate prompt\n",
    "# !ls data\n",
    "# import time\n",
    "# time.sleep(60*30)\n",
    "\n",
    "# Try to do:\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c4ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import transformers\n",
    "from peft import PeftModel\n",
    "from transformers import LlamaForCausalLM as LLaMAForCausalLM\n",
    "from transformers import LlamaTokenizer as LLaMATokenizer\n",
    "from peft import prepare_model_for_int8_training, LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "from EvaluateTestSet import EvaluateTestSet\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "def init_lora_model_and_tokenizer(default_model,\n",
    "                             LORA_R,\n",
    "                             LORA_ALPHA,\n",
    "                             LORA_DROPOUT\n",
    "                            ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    model = LLaMAForCausalLM.from_pretrained(\n",
    "    default_model,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    )\n",
    "    tokenizer = LLaMATokenizer.from_pretrained(\n",
    "        default_model, add_eos_token=True\n",
    "    )\n",
    "\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=LORA_R,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    tokenizer.pad_token_id = 0  # unk. we want this to be different from the eos token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "class MyCustomCallback(TensorBoardCallback):\n",
    "    #log_bleu_steps_factor = 5\n",
    "    bleu_generation_max_new_tokens = 30\n",
    "    bleu_fn_test_data = \"temp/t2c_answers.json\"\n",
    "    bleu_fn_etalon = \"temp/answers.json\"\n",
    "    log_step = 0\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        super().on_log(args, state, control, logs=logs, **kwargs)\n",
    "        #print(\"kwargs\", len(kwargs), kwargs.keys())\n",
    "        if self.tb_writer is not None:\n",
    "            #print(state)\n",
    "            #print(state.global_step)\n",
    "            #print(self.log_step)\n",
    "            if (self.log_step % self.log_bleu_steps_factor ==0):\n",
    "                model = kwargs['model']\n",
    "                tokenizer = kwargs['tokenizer']\n",
    "                \n",
    "                model.eval()\n",
    "                assert not model.training\n",
    "                generation_config = GenerationConfig(max_new_tokens = self.bleu_generation_max_new_tokens,\n",
    "                                                     # min_new_tokens = 5,\n",
    "                                                     temperature = 1.0\n",
    "                                                    )\n",
    "                print(\"generation_config:\", generation_config)\n",
    "                evaluator = EvaluateTestSet(generation_config = generation_config,\n",
    "                                            fn_test_data = self.bleu_fn_test_data,\n",
    "                                            fn_etalon = self.bleu_fn_etalon,\n",
    "                                            batch_size = 1\n",
    "                                       )\n",
    "\n",
    "                metric_res = evaluator.evaluate(model=model, \n",
    "                                                tokenizer=tokenizer,\n",
    "                                               )\n",
    "                model.train()\n",
    "                assert model.training\n",
    "                print(metric_res)\n",
    "                for key, val in metric_res.items():\n",
    "                    #add \"custom/something\"\n",
    "                    self.tb_writer.add_scalar(key, val, state.global_step)\n",
    "                self.tb_writer.flush()\n",
    "            self.log_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a58e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"/root/experiments_config/\"\n",
    "EXPERIMENTS_PATH = \"/root/experiments/\"\n",
    "experiment_name = \"t2c_concode_220428_v17\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc88f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_config_path = os.path.join(CONFIG_PATH, experiment_name + \"_config.json\")\n",
    "experiment_config = json.load(open(current_config_path, \"r\"))\n",
    "\n",
    "assert experiment_config['experiment_name'] == experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba1a9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config['resume_from_checkpoint'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50bb0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert experiment_config['resume_from_checkpoint'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc63c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert experiment_config['experiment_name'] == experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f52cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_experiment_path = os.path.join(EXPERIMENTS_PATH, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acf204b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/experiments/t2c_concode_220428_v16’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d7a3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(experiment_config, open(current_experiment_path + \\\n",
    "                                  \"/experiment_config.json\", \n",
    "                                  \"w+\"\n",
    "                                 )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3113e92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(MyCustomCallback, \"log_bleu_steps_factor\", experiment_config['log_bleu_steps_factor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68843904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyCustomCallback.log_bleu_steps_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e5bab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fd17e3b88d4788b2c3cc7a33f35a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n",
      "Found cached dataset json (/root/.cache/huggingface/datasets/json/default-3ac2744fedc77f2f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4520f42e31d14f2db6b50e02eb48474e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = init_lora_model_and_tokenizer(default_model = experiment_config[\"default_model\"],\n",
    "                                                 LORA_R = experiment_config[\"LORA_R\"],\n",
    "                                                 LORA_ALPHA = experiment_config[\"LORA_ALPHA\"],\n",
    "                                                 LORA_DROPOUT = experiment_config[\"LORA_DROPOUT\"]\n",
    "                                                )\n",
    "\n",
    "\n",
    "data = load_dataset(\"json\", \n",
    "                    data_files = {\"train\": experiment_config[\"fn_train_dataset\"],\n",
    "                                  \"eval\":  experiment_config[\"fn_eval_dataset\"]\n",
    "                                 }\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e83f74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_val = LLaMATokenizer.from_pretrained(\n",
    "    experiment_config['default_model'], add_eos_token=True\n",
    ")\n",
    "tokenizer_val.pad_token_id = 0  # unk. we want this to be different from the eos token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bec31c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config[\"logging_steps\"] = 1\n",
    "# experiment_config[\"eval_steps\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dfe7905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 't2c_concode_220428_v16',\n",
       " 'fn_train_dataset': '/root/data/t2c_train.json',\n",
       " 'fn_eval_dataset': '/root/data/t2c_answers.json',\n",
       " 'default_model': 'decapoda-research/llama-7b-hf',\n",
       " 'MICRO_BATCH_SIZE': 2,\n",
       " 'BATCH_SIZE': 10,\n",
       " 'EPOCHS': 2,\n",
       " 'LEARNING_RATE': 0.0002,\n",
       " 'CUTOFF_LEN': 256,\n",
       " 'LORA_R': 4,\n",
       " 'LORA_ALPHA': 16,\n",
       " 'LORA_DROPOUT': 0.05,\n",
       " 'warmup_steps': 200,\n",
       " 'fp16': True,\n",
       " 'logging_steps': 10,\n",
       " 'eval_steps': 100,\n",
       " 'evaluation_strategy': 'steps',\n",
       " 'save_total_limit': 1,\n",
       " 'save_strategy': 'steps',\n",
       " 'save_steps': 500,\n",
       " 'seed': 42,\n",
       " 'logging_strategy': 'steps',\n",
       " 'report_to': 'tensorboard',\n",
       " 'mlm': False,\n",
       " 'truncation': True,\n",
       " 'padding': 'max_length',\n",
       " 'config_use_cache': False,\n",
       " 'resume_from_checkpoint': True,\n",
       " 'bleu_batch_size': 5,\n",
       " 'GRADIENT_ACCUMULATION_STEPS': 5,\n",
       " 'log_bleu_steps_factor': 50}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8271f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config[\"resume_from_checkpoint\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3c1adb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ipynb/prompter/templates/\n"
     ]
    }
   ],
   "source": [
    "from prompter import Prompter\n",
    "prompter = Prompter()\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    if \"input\" in data_point and data_point[\"input\"]:\n",
    "        return prompter.generate_prompt(instruction = data_point[\"instruction\"],\n",
    "                                        input = data_point[\"input\"],\n",
    "                                        label = data_point[\"output\"]\n",
    "                                       )\n",
    "    else:\n",
    "        return prompter.generate_prompt(instruction = data_point[\"instruction\"],\n",
    "                                        #input = None,\n",
    "                                        label = data_point[\"output\"]\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5dce5420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19601' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19601/20000 21:41:12 < 27:11, 0.24 it/s, Epoch 1.96/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.975300</td>\n",
       "      <td>1.121514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.994600</td>\n",
       "      <td>1.116789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>1.115059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.941100</td>\n",
       "      <td>1.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.937800</td>\n",
       "      <td>1.110446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.935600</td>\n",
       "      <td>1.105852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.933100</td>\n",
       "      <td>1.107501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.910600</td>\n",
       "      <td>1.106961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.964800</td>\n",
       "      <td>1.104875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.970600</td>\n",
       "      <td>1.099931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.904300</td>\n",
       "      <td>1.101077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.897700</td>\n",
       "      <td>1.102762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.889800</td>\n",
       "      <td>1.102040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.908500</td>\n",
       "      <td>1.102287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.833100</td>\n",
       "      <td>1.104458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.883600</td>\n",
       "      <td>1.099695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.894500</td>\n",
       "      <td>1.095985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.944600</td>\n",
       "      <td>1.098494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.913100</td>\n",
       "      <td>1.095077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.861200</td>\n",
       "      <td>1.098835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.883800</td>\n",
       "      <td>1.099392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.940400</td>\n",
       "      <td>1.096846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.903400</td>\n",
       "      <td>1.097415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.934900</td>\n",
       "      <td>1.092952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.893200</td>\n",
       "      <td>1.094852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.843700</td>\n",
       "      <td>1.099033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.907800</td>\n",
       "      <td>1.095935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.880800</td>\n",
       "      <td>1.097291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.895400</td>\n",
       "      <td>1.097829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.887900</td>\n",
       "      <td>1.096843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.858700</td>\n",
       "      <td>1.092906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.912700</td>\n",
       "      <td>1.095156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.892100</td>\n",
       "      <td>1.094393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.884800</td>\n",
       "      <td>1.093327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.916300</td>\n",
       "      <td>1.094204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.901900</td>\n",
       "      <td>1.093701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>1.090986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.934200</td>\n",
       "      <td>1.091698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.869500</td>\n",
       "      <td>1.091900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.878400</td>\n",
       "      <td>1.096257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>1.097304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.884400</td>\n",
       "      <td>1.092336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.805800</td>\n",
       "      <td>1.095087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.839700</td>\n",
       "      <td>1.091806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.863100</td>\n",
       "      <td>1.091050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.887200</td>\n",
       "      <td>1.093826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>1.090367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.870600</td>\n",
       "      <td>1.090113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>1.094420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.827600</td>\n",
       "      <td>1.090982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.875200</td>\n",
       "      <td>1.090651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.872700</td>\n",
       "      <td>1.091173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.833000</td>\n",
       "      <td>1.091149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.873400</td>\n",
       "      <td>1.091877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.905200</td>\n",
       "      <td>1.094494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.919700</td>\n",
       "      <td>1.091891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.918400</td>\n",
       "      <td>1.090814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.891800</td>\n",
       "      <td>1.093385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.882100</td>\n",
       "      <td>1.091327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.754100</td>\n",
       "      <td>1.091819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.829500</td>\n",
       "      <td>1.091688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>1.090375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.854200</td>\n",
       "      <td>1.089252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.838100</td>\n",
       "      <td>1.091582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.839000</td>\n",
       "      <td>1.090979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.859500</td>\n",
       "      <td>1.091309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.834400</td>\n",
       "      <td>1.091136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.802600</td>\n",
       "      <td>1.089507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.872700</td>\n",
       "      <td>1.089892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.808400</td>\n",
       "      <td>1.088329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.840100</td>\n",
       "      <td>1.088433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.801500</td>\n",
       "      <td>1.089109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.837800</td>\n",
       "      <td>1.089578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.849600</td>\n",
       "      <td>1.091376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.850700</td>\n",
       "      <td>1.090098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>1.089425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.847600</td>\n",
       "      <td>1.090463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.853300</td>\n",
       "      <td>1.088064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.794300</td>\n",
       "      <td>1.089868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.880500</td>\n",
       "      <td>1.088838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.802700</td>\n",
       "      <td>1.086877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.818100</td>\n",
       "      <td>1.090188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>1.089435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.799200</td>\n",
       "      <td>1.090583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>1.090719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.868200</td>\n",
       "      <td>1.086855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.820500</td>\n",
       "      <td>1.087522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.875400</td>\n",
       "      <td>1.089116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.851700</td>\n",
       "      <td>1.091622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.851900</td>\n",
       "      <td>1.087547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.797700</td>\n",
       "      <td>1.086918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.810300</td>\n",
       "      <td>1.088339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.830200</td>\n",
       "      <td>1.090006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.789600</td>\n",
       "      <td>1.090067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.840700</td>\n",
       "      <td>1.088662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.869500</td>\n",
       "      <td>1.092128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.813100</td>\n",
       "      <td>1.089661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>1.093200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.849800</td>\n",
       "      <td>1.089846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.788500</td>\n",
       "      <td>1.092809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.791300</td>\n",
       "      <td>1.094185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.813300</td>\n",
       "      <td>1.091586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.810200</td>\n",
       "      <td>1.091066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.806900</td>\n",
       "      <td>1.091744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.831500</td>\n",
       "      <td>1.091613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.759700</td>\n",
       "      <td>1.091888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.823300</td>\n",
       "      <td>1.093004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.875400</td>\n",
       "      <td>1.087207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.762000</td>\n",
       "      <td>1.091538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.852200</td>\n",
       "      <td>1.090082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>1.088562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.768400</td>\n",
       "      <td>1.091448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.850300</td>\n",
       "      <td>1.090617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.814500</td>\n",
       "      <td>1.089930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.833600</td>\n",
       "      <td>1.089878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.789000</td>\n",
       "      <td>1.092440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.861400</td>\n",
       "      <td>1.090212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.814700</td>\n",
       "      <td>1.093543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>1.094388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.890400</td>\n",
       "      <td>1.092552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.755600</td>\n",
       "      <td>1.094450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.853200</td>\n",
       "      <td>1.088433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.829800</td>\n",
       "      <td>1.093796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>0.811900</td>\n",
       "      <td>1.093478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.784300</td>\n",
       "      <td>1.092630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13100</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.092013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.774900</td>\n",
       "      <td>1.089655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>0.818100</td>\n",
       "      <td>1.091258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.765600</td>\n",
       "      <td>1.091504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.786100</td>\n",
       "      <td>1.090227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.824700</td>\n",
       "      <td>1.088846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13700</td>\n",
       "      <td>0.815900</td>\n",
       "      <td>1.087498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.779800</td>\n",
       "      <td>1.090102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13900</td>\n",
       "      <td>0.789800</td>\n",
       "      <td>1.091381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.834300</td>\n",
       "      <td>1.089407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14100</td>\n",
       "      <td>0.741700</td>\n",
       "      <td>1.089159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.716800</td>\n",
       "      <td>1.093498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14300</td>\n",
       "      <td>0.791700</td>\n",
       "      <td>1.089668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.768900</td>\n",
       "      <td>1.091279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.815700</td>\n",
       "      <td>1.090251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.815300</td>\n",
       "      <td>1.091786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14700</td>\n",
       "      <td>0.768300</td>\n",
       "      <td>1.090358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.819000</td>\n",
       "      <td>1.090888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14900</td>\n",
       "      <td>0.768800</td>\n",
       "      <td>1.092258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.754400</td>\n",
       "      <td>1.090854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15100</td>\n",
       "      <td>0.782100</td>\n",
       "      <td>1.090742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.811400</td>\n",
       "      <td>1.091796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15300</td>\n",
       "      <td>0.802300</td>\n",
       "      <td>1.090155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>1.088749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.831600</td>\n",
       "      <td>1.088755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.864200</td>\n",
       "      <td>1.087537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15700</td>\n",
       "      <td>0.787900</td>\n",
       "      <td>1.089821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>0.843700</td>\n",
       "      <td>1.087180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15900</td>\n",
       "      <td>0.788800</td>\n",
       "      <td>1.089059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.798400</td>\n",
       "      <td>1.088582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16100</td>\n",
       "      <td>0.775500</td>\n",
       "      <td>1.090399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>0.824200</td>\n",
       "      <td>1.089104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16300</td>\n",
       "      <td>0.772400</td>\n",
       "      <td>1.089478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>0.758700</td>\n",
       "      <td>1.089900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.860900</td>\n",
       "      <td>1.086874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>0.789200</td>\n",
       "      <td>1.087716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16700</td>\n",
       "      <td>0.814100</td>\n",
       "      <td>1.089282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.809500</td>\n",
       "      <td>1.087818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16900</td>\n",
       "      <td>0.768900</td>\n",
       "      <td>1.088638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.850300</td>\n",
       "      <td>1.090343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17100</td>\n",
       "      <td>0.854100</td>\n",
       "      <td>1.088321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>0.817300</td>\n",
       "      <td>1.087994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17300</td>\n",
       "      <td>0.788400</td>\n",
       "      <td>1.088273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>0.698700</td>\n",
       "      <td>1.089978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.765200</td>\n",
       "      <td>1.087246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>0.887700</td>\n",
       "      <td>1.088024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17700</td>\n",
       "      <td>0.837400</td>\n",
       "      <td>1.088006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17800</td>\n",
       "      <td>0.813100</td>\n",
       "      <td>1.087058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17900</td>\n",
       "      <td>0.789600</td>\n",
       "      <td>1.089218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>1.089180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18100</td>\n",
       "      <td>0.766900</td>\n",
       "      <td>1.088521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18200</td>\n",
       "      <td>0.809400</td>\n",
       "      <td>1.087090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18300</td>\n",
       "      <td>0.784200</td>\n",
       "      <td>1.088192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18400</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>1.088014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.788500</td>\n",
       "      <td>1.088011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18600</td>\n",
       "      <td>0.732600</td>\n",
       "      <td>1.087102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18700</td>\n",
       "      <td>0.787300</td>\n",
       "      <td>1.088912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18800</td>\n",
       "      <td>0.836700</td>\n",
       "      <td>1.088840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18900</td>\n",
       "      <td>0.786300</td>\n",
       "      <td>1.087452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.827500</td>\n",
       "      <td>1.087571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19100</td>\n",
       "      <td>0.777700</td>\n",
       "      <td>1.088740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>1.086902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19300</td>\n",
       "      <td>0.790800</td>\n",
       "      <td>1.086511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19400</td>\n",
       "      <td>0.770300</td>\n",
       "      <td>1.087146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.752800</td>\n",
       "      <td>1.086904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.51s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 40226.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.09874452435765424, 'brevity_penalty': 0.5477365891588007, 'ratio': 0.6242350061199511, 'translation_length': 510, 'reference_length': 817, 'precisions_0': 0.44422700587084146, 'precisions_1': 0.24324324324324326, 'precisions_2': 0.1286031042128603, 'precisions_3': 0.07600950118764846}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.51s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 168445.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1647954059807245, 'brevity_penalty': 0.7215896154822341, 'ratio': 0.7539779681762546, 'translation_length': 616, 'reference_length': 817, 'precisions_0': 0.4959481361426256, 'precisions_1': 0.3049403747870528, 'precisions_2': 0.17235188509874327, 'precisions_3': 0.10436432637571158}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.51s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 149618.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21339055267271648, 'brevity_penalty': 0.6901782584838726, 'ratio': 0.7294981640146879, 'translation_length': 596, 'reference_length': 817, 'precisions_0': 0.5879396984924623, 'precisions_1': 0.3880070546737213, 'precisions_2': 0.24767225325884543, 'precisions_3': 0.16173570019723865}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.53s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 164267.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1636800065822104, 'brevity_penalty': 0.6516017749168791, 'ratio': 0.7001223990208079, 'translation_length': 572, 'reference_length': 817, 'precisions_0': 0.5218150087260035, 'precisions_1': 0.3259668508287293, 'precisions_2': 0.1949317738791423, 'precisions_3': 0.12008281573498965}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.48s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 54565.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.14813196820457947, 'brevity_penalty': 0.5391174748573048, 'ratio': 0.6181150550795593, 'translation_length': 505, 'reference_length': 817, 'precisions_0': 0.567193675889328, 'precisions_1': 0.35294117647058826, 'precisions_2': 0.21252796420581654, 'precisions_3': 0.1339712918660287}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.55s/it]\n",
      "\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 41432.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18834971437959735, 'brevity_penalty': 0.6237085593295825, 'ratio': 0.6793145654834761, 'translation_length': 555, 'reference_length': 817, 'precisions_0': 0.5539568345323741, 'precisions_1': 0.37072243346007605, 'precisions_2': 0.24193548387096775, 'precisions_3': 0.16738197424892703}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:41<00:00,  3.40s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 186690.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.10572539713850716, 'brevity_penalty': 0.36878000238976066, 'ratio': 0.5006119951040392, 'translation_length': 409, 'reference_length': 817, 'precisions_0': 0.6, 'precisions_1': 0.37894736842105264, 'precisions_2': 0.20797720797720798, 'precisions_3': 0.14285714285714285}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:39<00:00,  3.33s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 169581.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1583822269620903, 'brevity_penalty': 0.49730851122147096, 'ratio': 0.5887392900856793, 'translation_length': 481, 'reference_length': 817, 'precisions_0': 0.5767634854771784, 'precisions_1': 0.38495575221238937, 'precisions_2': 0.24881516587677724, 'precisions_3': 0.18622448979591838}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.53s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 168445.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.19817390458941755, 'brevity_penalty': 0.6901782584838726, 'ratio': 0.7294981640146879, 'translation_length': 596, 'reference_length': 817, 'precisions_0': 0.52428810720268, 'precisions_1': 0.3403880070546737, 'precisions_2': 0.2271880819366853, 'precisions_3': 0.16765285996055226}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.49s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 182361.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.17483226312341327, 'brevity_penalty': 0.5733892484737265, 'ratio': 0.642594859241126, 'translation_length': 525, 'reference_length': 817, 'precisions_0': 0.5437262357414449, 'precisions_1': 0.3629032258064516, 'precisions_2': 0.2398286937901499, 'precisions_3': 0.182648401826484}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.48s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 118706.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.14762765125661323, 'brevity_penalty': 0.6020708956175393, 'ratio': 0.6634026927784578, 'translation_length': 542, 'reference_length': 817, 'precisions_0': 0.5211786372007366, 'precisions_1': 0.30994152046783624, 'precisions_2': 0.18181818181818182, 'precisions_3': 0.12307692307692308}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.55s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 156309.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.12914933421099825, 'brevity_penalty': 0.5287314938218902, 'ratio': 0.6107711138310894, 'translation_length': 499, 'reference_length': 817, 'precisions_0': 0.47, 'precisions_1': 0.2957446808510638, 'precisions_2': 0.1873589164785553, 'precisions_3': 0.1366906474820144}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:39<00:00,  3.33s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 165130.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.17292199972923272, 'brevity_penalty': 0.558035145770047, 'ratio': 0.631578947368421, 'translation_length': 516, 'reference_length': 817, 'precisions_0': 0.5531914893617021, 'precisions_1': 0.3757700205338809, 'precisions_2': 0.2549019607843137, 'precisions_3': 0.1740139211136891}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:41<00:00,  3.38s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 190650.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.11084830985974978, 'brevity_penalty': 0.40656965974059905, 'ratio': 0.5263157894736842, 'translation_length': 430, 'reference_length': 817, 'precisions_0': 0.5081206496519721, 'precisions_1': 0.3266832917705736, 'precisions_2': 0.21390374331550802, 'precisions_3': 0.15561959654178675}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.50s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 184230.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.11918980126197876, 'brevity_penalty': 0.48498918271047725, 'ratio': 0.5801713586291309, 'translation_length': 474, 'reference_length': 817, 'precisions_0': 0.5389473684210526, 'precisions_1': 0.32808988764044944, 'precisions_2': 0.18854415274463007, 'precisions_3': 0.10941475826972011}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.53s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 56527.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1246026964775031, 'brevity_penalty': 0.47615861075053517, 'ratio': 0.5740514075887393, 'translation_length': 469, 'reference_length': 817, 'precisions_0': 0.5319148936170213, 'precisions_1': 0.32954545454545453, 'precisions_2': 0.20194647201946472, 'precisions_3': 0.13246753246753246}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.49s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 174278.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.19768500077886683, 'brevity_penalty': 0.6806236541219175, 'ratio': 0.7221542227662179, 'translation_length': 590, 'reference_length': 817, 'precisions_0': 0.5329949238578681, 'precisions_1': 0.34581105169340465, 'precisions_2': 0.231203007518797, 'precisions_3': 0.16699801192842942}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:44<00:00,  3.48s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 148910.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.19225404315019848, 'brevity_penalty': 0.635250001256266, 'ratio': 0.6878824969400245, 'translation_length': 562, 'reference_length': 817, 'precisions_0': 0.5612788632326821, 'precisions_1': 0.36585365853658536, 'precisions_2': 0.23856858846918488, 'precisions_3': 0.17124735729386892}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:38<00:00,  3.30s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 63550.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18364435455706254, 'brevity_penalty': 0.6220534596927131, 'ratio': 0.6780905752753978, 'translation_length': 554, 'reference_length': 817, 'precisions_0': 0.5333333333333333, 'precisions_1': 0.35619047619047617, 'precisions_2': 0.2383838383838384, 'precisions_3': 0.16774193548387098}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.47s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 162780.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21552423221013614, 'brevity_penalty': 0.6822202628155224, 'ratio': 0.7233782129742962, 'translation_length': 591, 'reference_length': 817, 'precisions_0': 0.5625, 'precisions_1': 0.37544483985765126, 'precisions_2': 0.2518796992481203, 'precisions_3': 0.18725099601593626}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.54s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 55309.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1762947677167243, 'brevity_penalty': 0.6758238404571268, 'ratio': 0.7184822521419829, 'translation_length': 587, 'reference_length': 817, 'precisions_0': 0.5221088435374149, 'precisions_1': 0.32974910394265233, 'precisions_2': 0.19696969696969696, 'precisions_3': 0.13654618473895583}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:38<00:00,  3.28s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 138731.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18643728686431643, 'brevity_penalty': 0.6237085593295825, 'ratio': 0.6793145654834761, 'translation_length': 555, 'reference_length': 817, 'precisions_0': 0.5611510791366906, 'precisions_1': 0.3650190114068441, 'precisions_2': 0.23588709677419356, 'precisions_3': 0.16523605150214593}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:42<00:00,  3.42s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 168220.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1953060133579098, 'brevity_penalty': 0.6499738697156315, 'ratio': 0.6988984088127295, 'translation_length': 571, 'reference_length': 817, 'precisions_0': 0.5384615384615384, 'precisions_1': 0.36162361623616235, 'precisions_2': 0.240234375, 'precisions_3': 0.17427385892116182}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.45s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 53025.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.205091515384775, 'brevity_penalty': 0.6253620853529512, 'ratio': 0.6805385556915544, 'translation_length': 556, 'reference_length': 817, 'precisions_0': 0.5727109515260324, 'precisions_1': 0.3889943074003795, 'precisions_2': 0.2635814889336016, 'precisions_3': 0.19700214132762311}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:42<00:00,  3.42s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 175249.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18138687916464194, 'brevity_penalty': 0.6286644024420278, 'ratio': 0.6829865361077111, 'translation_length': 558, 'reference_length': 817, 'precisions_0': 0.5491949910554562, 'precisions_1': 0.3553875236294896, 'precisions_2': 0.226, 'precisions_3': 0.15711252653927812}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.46s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 167103.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20419171319585533, 'brevity_penalty': 0.640172441475687, 'ratio': 0.6915544675642595, 'translation_length': 565, 'reference_length': 817, 'precisions_0': 0.549469964664311, 'precisions_1': 0.3805970149253731, 'precisions_2': 0.25889328063241107, 'precisions_3': 0.19117647058823528}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:42<00:00,  3.43s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 53159.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.17819869707799438, 'brevity_penalty': 0.6270140342187177, 'ratio': 0.6817625458996328, 'translation_length': 557, 'reference_length': 817, 'precisions_0': 0.532258064516129, 'precisions_1': 0.3484848484848485, 'precisions_2': 0.22645290581162325, 'precisions_3': 0.15531914893617021}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:43<00:00,  3.46s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 41268.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20079239045533986, 'brevity_penalty': 0.635250001256266, 'ratio': 0.6878824969400245, 'translation_length': 562, 'reference_length': 817, 'precisions_0': 0.5488454706927176, 'precisions_1': 0.3714821763602251, 'precisions_2': 0.2544731610337972, 'precisions_3': 0.19238900634249473}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▊                                      | 4/30 [00:14<01:32,  3.55s/it]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def generate_prompt(data_point):\n",
    "#     # sorry about the formatting disaster gotta move fast\n",
    "#     if data_point[\"input\"]:\n",
    "#         return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "# ### Instruction:\n",
    "# {data_point[\"instruction\"]}\n",
    "# ### Input:\n",
    "# {data_point[\"input\"]}\n",
    "# ### Response:\n",
    "# {data_point[\"output\"]}\"\"\"\n",
    "#     else:\n",
    "#         return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "# ### Instruction:\n",
    "# {data_point[\"instruction\"]}\n",
    "# ### Response:\n",
    "# {data_point[\"output\"]}\"\"\"\n",
    "\n",
    "\n",
    "data = data.shuffle().map(\n",
    "    lambda data_point: tokenizer(\n",
    "        generate_prompt(data_point),\n",
    "        truncation=experiment_config[\"truncation\"],\n",
    "        max_length=experiment_config[\"CUTOFF_LEN\"],\n",
    "        padding=experiment_config[\"padding\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer_val,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data['eval'],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=experiment_config[\"MICRO_BATCH_SIZE\"],\n",
    "        gradient_accumulation_steps=experiment_config[\"GRADIENT_ACCUMULATION_STEPS\"],\n",
    "        warmup_steps=experiment_config[\"warmup_steps\"],\n",
    "        num_train_epochs=experiment_config[\"EPOCHS\"],\n",
    "        learning_rate=experiment_config[\"LEARNING_RATE\"],\n",
    "        fp16=experiment_config[\"fp16\"],\n",
    "        logging_steps=experiment_config[\"logging_steps\"],        \n",
    "        evaluation_strategy = experiment_config['evaluation_strategy'],\n",
    "        eval_steps=experiment_config[\"eval_steps\"],\n",
    "        output_dir=current_experiment_path,#\"lora-alpaca\",\n",
    "        save_total_limit=experiment_config[\"save_total_limit\"],\n",
    "        save_strategy = experiment_config[\"save_strategy\"],\n",
    "        \n",
    "        save_steps = experiment_config[\"save_steps\"],\n",
    "        seed=experiment_config[\"seed\"],\n",
    "        logging_dir=current_experiment_path,\n",
    "        logging_strategy=experiment_config[\"logging_strategy\"],\n",
    "        report_to=experiment_config[\"report_to\"]\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, \n",
    "                                                               mlm=experiment_config[\"mlm\"]\n",
    "                                                              ),\n",
    "    callbacks = [MyCustomCallback]\n",
    ")\n",
    "model.config.use_cache = experiment_config[\"config_use_cache\"]\n",
    "# print(len(trainer.optimizer.state['found_inf_per_device']))\n",
    "\n",
    "\n",
    "trainer.train(resume_from_checkpoint=experiment_config[\"resume_from_checkpoint\"])\n",
    "\n",
    "model.save_pretrained(current_experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "665c1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(current_experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e72383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a8f14bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n",
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay          45G   45G  136K 100% /\r\n"
     ]
    }
   ],
   "source": [
    "!df -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e99e9020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 52K\r\n",
      "drwxr-xr-x  6 root root 251 May  7 21:16 .\r\n",
      "drwxr-xr-x 10 root root 245 May  7 20:04 ..\r\n",
      "drwxr-xr-x  2 root root  65 May  7 20:07 1683490028.7076824\r\n",
      "drwxr-xr-x  2 root root  65 May  7 20:07 1683490028.7192707\r\n",
      "drwxr-xr-x  2 root root  31 May  7 21:16 checkpoint-1000\r\n",
      "drwxr-xr-x  2 root root 243 May  7 20:42 checkpoint-500\r\n",
      "-rw-r--r--  1 root root 22K May  7 21:16 events.out.tfevents.1683490028.8d048d63ed1a.12197.0\r\n",
      "-rw-r--r--  1 root root 24K May  7 21:16 events.out.tfevents.1683490028.8d048d63ed1a.12197.2\r\n",
      "-rw-r--r--  1 root root 792 May  7 21:27 experiment_config.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c181738d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf {current_experiment_path}/checkpoint-1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d143e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /root/experiments/t2c_concode_220428_v16/checkpoint-20000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b571de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay          45G   26G   20G  58% /\r\n"
     ]
    }
   ],
   "source": [
    "!df -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca6142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
