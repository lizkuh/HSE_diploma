{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "import tqdm\n",
    "\n",
    "from T2CEvaluator import T2CEvaluator\n",
    "\n",
    "from prompter import Prompter\n",
    "prompter = Prompter()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    #assert 'output' not in data_point or data_point['output']==''\n",
    "    if \"input\" in data_point and data_point[\"input\"]:\n",
    "        return prompter.generate_prompt(instruction = data_point[\"instruction\"],\n",
    "                                        input = data_point[\"input\"],\n",
    "                                        #label = ''#data_point[\"output\"]\n",
    "                                       )\n",
    "    else:\n",
    "        return prompter.generate_prompt(instruction = data_point[\"instruction\"],\n",
    "                                        #input = None,\n",
    "                                        #label = ''#data_point[\"output\"]\n",
    "                                       )\n",
    "   \n",
    "# def generate_test_prompt(data_point, train = False):\n",
    "#     # To decrease expectations of results :)\n",
    "#     assert train == False\n",
    "#     # sorry about the formatting disaster gotta move fast\n",
    "#     if data_point[\"input\"]:\n",
    "#         return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "# ### Instruction:\n",
    "# {data_point[\"instruction\"]}\n",
    "\n",
    "# ### Input:\n",
    "# {data_point[\"input\"]}\n",
    "\n",
    "# ### Response:\n",
    "# {data_point[\"output\"] if train else ''}\"\"\"\n",
    "#     else:\n",
    "#         return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "# ### Instruction:\n",
    "# {data_point[\"instruction\"]}\n",
    "\n",
    "# ### Response:\n",
    "# {data_point[\"output\"] if train else ''}\"\"\"\n",
    "\n",
    "\n",
    "class EvaluateTestSet:\n",
    "    def __init__(self, \n",
    "                 generation_config = GenerationConfig(max_new_tokens = 128), \n",
    "                 fn_test_data = \"../data/t2c_answers.json\",\n",
    "                 fn_etalon = \"/root/data/answers.json\",\n",
    "                 batch_size = 10,\n",
    "                 verbose = False\n",
    "                ):\n",
    "        self.generation_config = generation_config\n",
    "        \n",
    "        self.fn_test_data = fn_test_data\n",
    "        self.fn_etalon = fn_etalon\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "       \n",
    "    def preprocess(self, s):\n",
    "        #ToDo rewrite it using Promt Template\n",
    "        #prompter.get_response(s)\n",
    "        s = s.split('### Response:\\n')[-1]#.split(\"### Input\")[0]\n",
    "        s = s.replace('\\n', '  ')\n",
    "        s = s.replace('<unk>', \" \")\n",
    "        s = ' '.join(s.split(' ')[:100])\n",
    "        while '  ' in s:\n",
    "            s = s.replace('  ', ' ')\n",
    "\n",
    "        if len(s) > 0 and s[0] == ' ':\n",
    "            s = s[1:]\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(s)\n",
    "        \n",
    "        return s\n",
    "\n",
    "    def clean_results(self, res_list):\n",
    "        predict_list = []\n",
    "        for s in tqdm.tqdm(res_list):\n",
    "            predict_list.append(self.preprocess(s))\n",
    "        return predict_list\n",
    "    \n",
    "    def get_raw_results(self, model, tokenizer, prompts):\n",
    "        batch_size = self.batch_size\n",
    "        generation_config = self.generation_config\n",
    "        \n",
    "        res_list = []\n",
    "        n = math.ceil(len(prompts)/batch_size)\n",
    "        \n",
    "        for ind in tqdm.tqdm(range(n)):\n",
    "            current_prompts = prompts[ind*batch_size: (ind+1)*batch_size]\n",
    "            if self.verbose:\n",
    "                print(ind * batch_size, (ind+1)*batch_size, len(current_prompts))\n",
    "\n",
    "            tokenized_inputs = tokenizer(list(current_prompts), \n",
    "                                         padding=True, \n",
    "                                         truncation=True, \n",
    "                                         return_tensors=\"pt\"\n",
    "                                        ).to('cuda')\n",
    "\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "                full_output = model.generate(\n",
    "                    **tokenized_inputs,\n",
    "                    generation_config=generation_config\n",
    "                )\n",
    "\n",
    "            res_list.extend(tokenizer.batch_decode(full_output, skip_special_tokens=False))\n",
    "        \n",
    "        return res_list\n",
    "    \n",
    "    def save_results(self, predict_list):\n",
    "        output_filename = str(datetime.now()).split('.')[0].replace(' ', '-').replace(':', '_')+'.txt'\n",
    "        fn_output = \"/root/results/%s\"%output_filename\n",
    "        \n",
    "        res = '\\n'.join([i if i!='' else '-' for i in predict_list])\n",
    "        open(fn_output, \"w+\", encoding='utf-8').write(res)\n",
    "        return fn_output\n",
    "    \n",
    "    def evaluate(self, model, tokenizer):\n",
    "        model.eval()\n",
    "        assert model.training == False\n",
    "\n",
    "        lst = json.load(open(self.fn_test_data, 'rb'))\n",
    "        inputs = lst# [lst[0]]\n",
    "        # instruction = 'Combine the question and answer into an image caption as succinctly as possible. Be sure to include the phrase \"a photo of\". Do not draw false conclusions.'\n",
    "        # inputs = ['Is this a baseball game? yes', 'Is this a baseball game? no']\n",
    "        prompts = [generate_test_prompt(inp) for inp in inputs]\n",
    "        prompts = np.array(prompts)\n",
    "        \n",
    "        res_list = self.get_raw_results(model = model, \n",
    "                                        tokenizer = tokenizer,\n",
    "                                        prompts = prompts)\n",
    "        \n",
    "        model.train()\n",
    "        assert model.training == True\n",
    "        \n",
    "        predict_list = self.clean_results(res_list)\n",
    "        \n",
    "        self.fn_output = self.save_results(predict_list)\n",
    "        \n",
    "        t2c_evaluator = T2CEvaluator()\n",
    "        metric_res = t2c_evaluator.calculate_metrics(fn_answers = self.fn_etalon, \n",
    "                                                     fn_predictions = self.fn_output\n",
    "                                                     )\n",
    "        return metric_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f57a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_model_tokenizer_from_pretrained\n",
    "import pandas as pd\n",
    "from transformers import GenerationConfig\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "default_model = \"decapoda-research/llama-7b-hf\"\n",
    "experiment_name = \"/root/experiments/t2c_concode_220428_v19/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9a83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = load_model_tokenizer_from_pretrained(default_model = default_model, \n",
    "                                                        experiment_name = experiment_name\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece7fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EvaluateTestSet(generation_config = GenerationConfig(max_new_tokens = 49\n",
    "                                                                ),\n",
    "                            #fn_test_data = \"temp/t2c_answers.json\",\n",
    "                            #fn_etalon = \"temp/answers.json\"\n",
    "                            batch_size = 10\n",
    "                           )\n",
    "\n",
    "metric_res = evaluator.evaluate(model=model, \n",
    "                                tokenizer=tokenizer,\n",
    "                               )\n",
    "# for key, val in generation_config_dict.items():\n",
    "#     assert key not in metric_res\n",
    "#     metric_res[key] = val\n",
    "\n",
    "metric_res['experiment_name'] = experiment_name\n",
    "metric_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38cf379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_length = 1024\n",
    "\n",
    "# max_length = 400, \n",
    "# {'EM': 0.0,\n",
    "#  'BLEU': 0.20770774117978485,\n",
    "#  'brevity_penalty': 0.7887852726079982,\n",
    "#  'ratio': 0.8082368082368082,\n",
    "#  'translation_length': 2512,\n",
    "#  'reference_length': 3108,\n",
    "#  'precisions_0': 0.4341424592120971,\n",
    "#  'precisions_1': 0.3033568172399503,\n",
    "#  'precisions_2': 0.2197195070123247,\n",
    "#  'precisions_3': 0.1661578717836895,\n",
    "#  'experiment_name': '/root/experiments/t2c_concode_220428_v19/'\n",
    "# }\n",
    "\n",
    "# max_length = 256, BLEU =  7.106139847448361e-12\n",
    "\n",
    "\n",
    "# title = \"best result ever\", max_length = 512\n",
    "# {'EM': 0.0,\n",
    "#  'BLEU': 0.19442009681675598,\n",
    "#  'brevity_penalty': 1.0,\n",
    "#  'ratio': 1.4996782496782497,\n",
    "#  'translation_length': 4661,\n",
    "#  'reference_length': 3108,\n",
    "#  'precisions_0': 0.3344058344058344,\n",
    "#  'precisions_1': 0.22709338009644892,\n",
    "#  'precisions_2': 0.1598479767493852,\n",
    "#  'precisions_3': 0.1177007299270073,\n",
    "#  'max_length': 512,\n",
    "#  'experiment_name': '/root/experiments/t2c_concode_220428_v19/'}\n",
    "\n",
    "# title = \"best result ever\", max_length = 512\n",
    "# {'EM': 0.0,\n",
    "#  'BLEU': 0.3069243409072005,\n",
    "#  'brevity_penalty': 0.8743219831966469,\n",
    "#  'ratio': 0.8815958815958816,\n",
    "#  'translation_length': 2740,\n",
    "#  'reference_length': 3108,\n",
    "#  'precisions_0': 0.5618387449835827,\n",
    "#  'precisions_1': 0.40931465354032565,\n",
    "#  'precisions_2': 0.2975206611570248,\n",
    "#  'precisions_3': 0.22194922194922195,\n",
    "#  'max_new_tokens': 49,\n",
    "#  'experiment_name': '/root/experiments/t2c_concode_220428_v19/'\n",
    "# }\n",
    "\n",
    "\n",
    "# title = \"best result ever\", batch_size = 20\n",
    "# {'EM': 0.0,\n",
    "#  'BLEU': 0.3069243409072005,\n",
    "#  'brevity_penalty': 0.8743219831966469,\n",
    "#  'ratio': 0.8815958815958816,\n",
    "#  'translation_length': 2740,\n",
    "#  'reference_length': 3108,\n",
    "#  'precisions_0': 0.5618387449835827,\n",
    "#  'precisions_1': 0.40931465354032565,\n",
    "#  'precisions_2': 0.2975206611570248,\n",
    "#  'precisions_3': 0.22194922194922195,\n",
    "#  'max_new_tokens': 49,\n",
    "#  'experiment_name': '/root/experiments/t2c_concode_220428_v19/'\n",
    "# }\n",
    "\n",
    "# title = \"best result ever\", batch_size = 5\n",
    "# {'EM': 0.0,\n",
    "#  'BLEU': 0.3094605290687326,\n",
    "#  'brevity_penalty': 0.8757688775902636,\n",
    "#  'ratio': 0.8828828828828829,\n",
    "#  'translation_length': 2744,\n",
    "#  'reference_length': 3108,\n",
    "#  'precisions_0': 0.5632058287795992,\n",
    "#  'precisions_1': 0.4109640831758034,\n",
    "#  'precisions_2': 0.29901768172888016,\n",
    "#  'precisions_3': 0.22526573998364677,\n",
    "#  'max_new_tokens': 49,\n",
    "#  'experiment_name': '/root/experiments/t2c_concode_220428_v19/'\n",
    "# }\n",
    "\n",
    "# title = (\"best result ever\"|\"t2c_concode_220428_v19\"), batch_size = {None|10}\n",
    "# {'EM': 0.0,\n",
    "#  'BLEU': 0.31417807176317536,\n",
    "#  'brevity_penalty': 0.8993798379997678,\n",
    "#  'ratio': 0.9041184041184042,\n",
    "#  'translation_length': 2810,\n",
    "#  'reference_length': 3108,\n",
    "#  'precisions_0': 0.5592315901814301,\n",
    "#  'precisions_1': 0.40575433419402435,\n",
    "#  'precisions_2': 0.2949061662198391,\n",
    "#  'precisions_3': 0.22253184713375795,\n",
    "#  'max_new_tokens': 49,\n",
    "#  'experiment_name': '/root/experiments/t2c_concode_220428_v19/'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
