{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c4b774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/root/HSE_diploma/\")\n",
    "sys.path.append(\"/root/HSE_diploma/evaluator/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a26c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import load_model_tokenizer_from_pretrained, draw_metrics_compare_with_glue\n",
    "from ParamsIterator import ParamsIterator\n",
    "from EvaluateTestSet import EvaluateTestSet\n",
    "import pandas as pd\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4369c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_model = \"yahma/llama-7b-hf\"\n",
    "experiment_name = \"/root/experiments/t2c_concode_220428_v37/\"\n",
    "default_model = json.load(open(\"/root/experiments/t2c_concode_220428_v37/experiment_config.json\", \"r\"))['default_model']\n",
    "params_iteration = {\"temperature\": [1.0],\n",
    "                    \"max_new_tokens\": [300]#None, 20, 30, 35, 40, 50, 60, 70, 80, 90, 100] + [45, 47, 49, 51, 53, 55]\n",
    "                   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd57c17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/root/experiments/t2c_concode_220428_v37/',\n",
       " {'temperature': [1.0], 'max_new_tokens': [300]})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name, params_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68a83cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6bc1c555e4480980eced946ae7b445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer, model = load_model_tokenizer_from_pretrained(default_model = default_model, \n",
    "                                                        experiment_name = experiment_name\n",
    "                                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c311271d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pad_token_id 0\n",
      "tokenizer.eos_token_id 2\n",
      "tokenizer.bos_token_id 1\n",
      "tokenizer.eos_token_id 2\n",
      "model.config.pad_token_id 0\n",
      "model.config.eos_token_id 2\n",
      "model.config.bos_token_id 1\n",
      "model.config.eos_token_id 2\n",
      "trainable params: 0 || all params: 6746804224 || trainable%: 0.0\n"
     ]
    }
   ],
   "source": [
    "def verbose_model_tokenizer(model, tokenizer):\n",
    "    print(\"tokenizer.pad_token_id\", tokenizer.pad_token_id)\n",
    "    print(\"tokenizer.eos_token_id\", tokenizer.eos_token_id)\n",
    "    print(\"tokenizer.bos_token_id\", tokenizer.bos_token_id)\n",
    "    print(\"tokenizer.eos_token_id\", tokenizer.eos_token_id)\n",
    "\n",
    "    print(\"model.config.pad_token_id\", model.config.pad_token_id)\n",
    "    print(\"model.config.eos_token_id\", model.config.eos_token_id)\n",
    "    print(\"model.config.bos_token_id\", model.config.bos_token_id)\n",
    "    print(\"model.config.eos_token_id\", model.config.eos_token_id)\n",
    "    model.print_trainable_parameters()\n",
    "    \n",
    "verbose_model_tokenizer(model, tokenizer)\n",
    "\n",
    "# tokenizer.pad_token_id 0\n",
    "# tokenizer.eos_token_id 2\n",
    "# tokenizer.bos_token_id 1\n",
    "# tokenizer.eos_token_id 2\n",
    "# model.config.pad_token_id 0\n",
    "# model.config.eos_token_id 2\n",
    "# model.config.bos_token_id 1\n",
    "# model.config.eos_token_id 2\n",
    "# trainable params: 0 || all params: 6746804224 || trainable%: 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aeb449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def get_metric_res(model, tokenizer, params_iteration, experiment_name):\n",
    "    res = []\n",
    "    for generation_config_dict in tqdm_notebook(ParamsIterator(params_iteration=params_iteration)):\n",
    "        evaluator = EvaluateTestSet(generation_config = GenerationConfig(**generation_config_dict\n",
    "                                                                        ),\n",
    "                                    \n",
    "                                    #fn_test_data = \"temp/t2c_answers.json\",\n",
    "                                    #fn_etalon = \"temp/answers.json\"\n",
    "                                   )\n",
    "\n",
    "        metric_res = evaluator.evaluate(model=model, \n",
    "                                        tokenizer=tokenizer                                        \n",
    "                                       )\n",
    "        for key, val in generation_config_dict.items():\n",
    "            assert key not in metric_res\n",
    "            metric_res[key] = val\n",
    "\n",
    "        metric_res['experiment_name'] = experiment_name\n",
    "        print(generation_config_dict, metric_res)\n",
    "\n",
    "        res.append(metric_res)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f6d34a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id = model.config.pad_token_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d40d9da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eb35342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3481/3839643825.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for generation_config_dict in tqdm_notebook(ParamsIterator(params_iteration=params_iteration)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb75eb8a980240c6b96b4d3c9f074dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[AAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "\n",
      " 10%|████▍                                       | 1/10 [00:13<01:57, 13.03s/it]\u001b[A\n",
      " 20%|████████▊                                   | 2/10 [01:11<05:17, 39.69s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 3/10 [01:20<03:00, 25.75s/it]\u001b[A\n",
      " 40%|█████████████████▌                          | 4/10 [01:26<01:47, 17.93s/it]\u001b[A\n",
      " 50%|██████████████████████                      | 5/10 [01:39<01:21, 16.29s/it]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 6/10 [01:56<01:05, 16.34s/it]\u001b[A\n",
      " 70%|██████████████████████████████▊             | 7/10 [02:06<00:42, 14.18s/it]\u001b[A\n",
      " 80%|███████████████████████████████████▏        | 8/10 [03:03<00:55, 27.92s/it]\u001b[A\n",
      " 90%|███████████████████████████████████████▌    | 9/10 [03:23<00:25, 25.52s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████| 10/10 [03:30<00:00, 21.08s/it]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████| 100/100 [00:00<00:00, 32221.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_new_tokens': 300, 'temperature': 1.0} {'EM': 0.0, 'BLEU': 0.0006187833664486746, 'brevity_penalty': 0.30601594809335797, 'ratio': 0.45785070785070786, 'translation_length': 1423, 'reference_length': 3108, 'precisions_0': 0.03651685393258427, 'precisions_1': 0.0007552870090634441, 'precisions_2': 0.0007710100231303007, 'precisions_3': 0.0007861635220125787, 'max_new_tokens': 300, 'temperature': 1.0, 'experiment_name': '/root/experiments/t2c_concode_220428_v37/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'EM': 0.0,\n",
       "  'BLEU': 0.0006187833664486746,\n",
       "  'brevity_penalty': 0.30601594809335797,\n",
       "  'ratio': 0.45785070785070786,\n",
       "  'translation_length': 1423,\n",
       "  'reference_length': 3108,\n",
       "  'precisions_0': 0.03651685393258427,\n",
       "  'precisions_1': 0.0007552870090634441,\n",
       "  'precisions_2': 0.0007710100231303007,\n",
       "  'precisions_3': 0.0007861635220125787,\n",
       "  'max_new_tokens': 300,\n",
       "  'temperature': 1.0,\n",
       "  'experiment_name': '/root/experiments/t2c_concode_220428_v37/'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3 = get_metric_res(model=model,\n",
    "                     tokenizer=tokenizer,\n",
    "                     params_iteration=params_iteration,\n",
    "                     experiment_name=experiment_name\n",
    "                    )\n",
    "res3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "717b51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompter import prompter, get_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a71f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"### Response:\n",
    "TernaryBool function ( ) { return canBeInstantiated ( ) ; }</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
    "===\n",
    "<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Generate java code\n",
    "interpret a short as its binary form \n",
    "\n",
    "### Input:\n",
    " PlaceHolder placeHolder \n",
    "\n",
    " long asLong \n",
    " int toInt \n",
    " String toBinaryString \n",
    " String toBinaryString \n",
    " String toBinaryString \n",
    " byte[] fromInt \n",
    " byte[] fromLong\n",
    "\n",
    "### Response:\n",
    "short function ( final short arg0 ) { return ( short ) ( arg0 & 0xFFFF ) ; }</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efa0b4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "TernaryBool function ( ) { return canBeInstantiated ( ) ; }</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
      "===\n",
      "<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate java code\n",
      "interpret a short as its binary form \n",
      "\n",
      "### Input:\n",
      " PlaceHolder placeHolder \n",
      "\n",
      " long asLong \n",
      " int toInt \n",
      " String toBinaryString \n",
      " String toBinaryString \n",
      " String toBinaryString \n",
      " byte[] fromInt \n",
      " byte[] fromLong\n",
      "\n",
      "### Response:\n",
      "short function ( final short arg0 ) { return ( short ) ( arg0 & 0xFFFF ) ; }</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
      "===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'### Response: TernaryBool function ( ) { return canBeInstantiated ( ) ; }</s> === '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = EvaluateTestSet()\n",
    "o.preprocess(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f4619f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "TernaryBool function ( ) { return canBeInstantiated ( ) ; }</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
      "===\n",
      "<unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate java code\n",
      "interpret a short as its binary form \n",
      "\n",
      "### Input:\n",
      " PlaceHolder placeHolder \n",
      "\n",
      " long asLong \n",
      " int toInt \n",
      " String toBinaryString \n",
      " String toBinaryString \n",
      " String toBinaryString \n",
      " byte[] fromInt \n",
      " byte[] fromLong\n",
      "\n",
      "### Response:\n",
      "short function ( final short arg0 ) { return ( short ) ( arg0 & 0xFFFF ) ; }</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n",
      "===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'short function ( final short arg0 ) { return ( short ) ( arg0 & 0xFFFF ) ; }</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfcbb640",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1969/3839643825.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for generation_config_dict in tqdm_notebook(ParamsIterator(params_iteration=params_iteration)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da2942de5404d04b42ed2316347c13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[AAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "\n",
      " 10%|████▍                                       | 1/10 [00:09<01:22,  9.13s/it]\u001b[A\n",
      " 20%|████████▊                                   | 2/10 [00:38<02:47, 20.95s/it]\u001b[A\n",
      " 30%|█████████████▏                              | 3/10 [00:46<01:44, 14.89s/it]\u001b[A\n",
      " 40%|█████████████████▌                          | 4/10 [00:53<01:12, 12.01s/it]\u001b[A\n",
      " 50%|██████████████████████                      | 5/10 [01:07<01:03, 12.65s/it]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 6/10 [01:27<01:00, 15.21s/it]\u001b[A\n",
      " 70%|██████████████████████████████▊             | 7/10 [01:38<00:41, 13.73s/it]\u001b[A\n",
      " 80%|███████████████████████████████████▏        | 8/10 [01:50<00:26, 13.38s/it]\u001b[A\n",
      " 90%|███████████████████████████████████████▌    | 9/10 [02:02<00:12, 12.91s/it]\u001b[A\n",
      "100%|███████████████████████████████████████████| 10/10 [02:15<00:00, 13.54s/it]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████| 100/100 [00:00<00:00, 34314.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_new_tokens': 200, 'temperature': 1.0} {'EM': 0.0, 'BLEU': 0.0006187833664486746, 'brevity_penalty': 0.30601594809335797, 'ratio': 0.45785070785070786, 'translation_length': 1423, 'reference_length': 3108, 'precisions_0': 0.03651685393258427, 'precisions_1': 0.0007552870090634441, 'precisions_2': 0.0007710100231303007, 'precisions_3': 0.0007861635220125787, 'max_new_tokens': 200, 'temperature': 1.0, 'experiment_name': '/root/experiments/t2c_concode_220428_v34/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'EM': 0.0,\n",
       "  'BLEU': 0.0006187833664486746,\n",
       "  'brevity_penalty': 0.30601594809335797,\n",
       "  'ratio': 0.45785070785070786,\n",
       "  'translation_length': 1423,\n",
       "  'reference_length': 3108,\n",
       "  'precisions_0': 0.03651685393258427,\n",
       "  'precisions_1': 0.0007552870090634441,\n",
       "  'precisions_2': 0.0007710100231303007,\n",
       "  'precisions_3': 0.0007861635220125787,\n",
       "  'max_new_tokens': 200,\n",
       "  'temperature': 1.0,\n",
       "  'experiment_name': '/root/experiments/t2c_concode_220428_v34/'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7c0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
