{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ac0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All to folder\n",
    "## generate prompt\n",
    "# !ls data\n",
    "# import time\n",
    "# time.sleep(60*30)\n",
    "\n",
    "# Try to do:\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c4ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import transformers\n",
    "from peft import PeftModel\n",
    "from transformers import LlamaForCausalLM as LLaMAForCausalLM\n",
    "from transformers import LlamaTokenizer as LLaMATokenizer\n",
    "from peft import prepare_model_for_int8_training, LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "from EvaluateTestSet import EvaluateTestSet\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "def init_lora_model_and_tokenizer(default_model,\n",
    "                             LORA_R,\n",
    "                             LORA_ALPHA,\n",
    "                             LORA_DROPOUT\n",
    "                            ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    model = LLaMAForCausalLM.from_pretrained(\n",
    "    default_model,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    )\n",
    "    tokenizer = LLaMATokenizer.from_pretrained(\n",
    "        default_model, add_eos_token=True\n",
    "    )\n",
    "\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=LORA_R,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    tokenizer.pad_token_id = 0  # unk. we want this to be different from the eos token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "class MyCustomCallback(TensorBoardCallback):\n",
    "    #log_bleu_steps_factor = 5\n",
    "    bleu_generation_max_new_tokens = 30\n",
    "    bleu_fn_test_data = \"temp/t2c_answers.json\"\n",
    "    bleu_fn_etalon = \"temp/answers.json\"\n",
    "    log_step = 0\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        super().on_log(args, state, control, logs=logs, **kwargs)\n",
    "        #print(\"kwargs\", len(kwargs), kwargs.keys())\n",
    "        if self.tb_writer is not None:\n",
    "            #print(state)\n",
    "            #print(state.global_step)\n",
    "            #print(self.log_step)\n",
    "            if (self.log_step % self.log_bleu_steps_factor ==0):\n",
    "                model = kwargs['model']\n",
    "                tokenizer = kwargs['tokenizer']\n",
    "                \n",
    "                model.eval()\n",
    "                assert not model.training\n",
    "                generation_config = GenerationConfig(max_new_tokens = self.bleu_generation_max_new_tokens,\n",
    "                                                     # min_new_tokens = 5,\n",
    "                                                     temperature = 1.0\n",
    "                                                    )\n",
    "                print(\"generation_config:\", generation_config)\n",
    "                evaluator = EvaluateTestSet(generation_config = generation_config,\n",
    "                                            fn_test_data = self.bleu_fn_test_data,\n",
    "                                            fn_etalon = self.bleu_fn_etalon,\n",
    "                                            batch_size = 1\n",
    "                                       )\n",
    "\n",
    "                metric_res = evaluator.evaluate(model=model, \n",
    "                                                tokenizer=tokenizer,\n",
    "                                               )\n",
    "                model.train()\n",
    "                assert model.training\n",
    "                print(metric_res)\n",
    "                for key, val in metric_res.items():\n",
    "                    #add \"custom/something\"\n",
    "                    self.tb_writer.add_scalar(key, val, state.global_step)\n",
    "                self.tb_writer.flush()\n",
    "            self.log_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81b76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list\n",
    "# !pip install bitsandbytes==0.37.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a58e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"/root/experiments_configs/\"\n",
    "EXPERIMENTS_PATH = \"/root/experiments/\"\n",
    "experiment_name = \"t2c_concode_220428_v31\"\n",
    "# t2c_concode_220428_v18.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51baf7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2c_concode_220428_v14_config.json  t2c_concode_220428_v20_config.json\r\n",
      "t2c_concode_220428_v15_config.json  t2c_concode_220428_v22_config.json\r\n",
      "t2c_concode_220428_v16_config.json  t2c_concode_220428_v30_config.json\r\n",
      "t2c_concode_220428_v18_config.json  t2c_concode_220428_v31.json\r\n",
      "t2c_concode_220428_v19_config.json  t2c_concode_220428_v31_config.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls /root/experiments_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c96309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc88f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_config_path = os.path.join(CONFIG_PATH, experiment_name + \"_config.json\")\n",
    "experiment_config = json.load(open(current_config_path, \"r\"))\n",
    "\n",
    "assert experiment_config['experiment_name'] == experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eff1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config['resume_from_checkpoint'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50bb0a80",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m experiment_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresume_from_checkpoint\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert experiment_config['resume_from_checkpoint'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dc63c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert experiment_config['experiment_name'] == experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f52cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_experiment_path = os.path.join(EXPERIMENTS_PATH, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acf204b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d7a3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(experiment_config, open(current_experiment_path + \\\n",
    "                                  \"/experiment_config.json\", \n",
    "                                  \"w+\"\n",
    "                                 )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "946d5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(MyCustomCallback, \"log_bleu_steps_factor\", experiment_config['log_bleu_steps_factor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63e33b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyCustomCallback.log_bleu_steps_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e5bab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5308255b58624fc7ac2b738fbbfae7a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-3ac2744fedc77f2f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd165d3d6a14e2eb88ce358c080431a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f021d107b8c0407db10890dfbdcd690d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating eval split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-3ac2744fedc77f2f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67873f235b04b3f9f7264efa96fdb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = init_lora_model_and_tokenizer(default_model = experiment_config[\"default_model\"],\n",
    "                                                 LORA_R = experiment_config[\"LORA_R\"],\n",
    "                                                 LORA_ALPHA = experiment_config[\"LORA_ALPHA\"],\n",
    "                                                 LORA_DROPOUT = experiment_config[\"LORA_DROPOUT\"]\n",
    "                                                )\n",
    "\n",
    "\n",
    "data = load_dataset(\"json\", \n",
    "                    data_files = {\"train\": experiment_config[\"fn_train_dataset\"],\n",
    "                                  \"eval\":  experiment_config[\"fn_eval_dataset\"]\n",
    "                                 }\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e83f74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_val = LLaMATokenizer.from_pretrained(\n",
    "    experiment_config['default_model'], add_eos_token=True\n",
    ")\n",
    "tokenizer_val.pad_token_id = 0  # unk. we want this to be different from the eos token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a58aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config[\"logging_steps\"] = 1\n",
    "# experiment_config[\"eval_steps\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "415d4e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 't2c_concode_220428_v31',\n",
       " 'fn_train_dataset': '/root/data/t2c_train.json',\n",
       " 'fn_eval_dataset': '/root/data/t2c_answers.json',\n",
       " 'default_model': 'decapoda-research/llama-7b-hf',\n",
       " 'MICRO_BATCH_SIZE': 2,\n",
       " 'BATCH_SIZE': 10,\n",
       " 'EPOCHS': 2,\n",
       " 'LEARNING_RATE': 0.0002,\n",
       " 'CUTOFF_LEN': 256,\n",
       " 'LORA_R': 1024,\n",
       " 'LORA_ALPHA': 1024,\n",
       " 'LORA_DROPOUT': 0.05,\n",
       " 'warmup_steps': 200,\n",
       " 'fp16': True,\n",
       " 'logging_steps': 10,\n",
       " 'eval_steps': 100,\n",
       " 'evaluation_strategy': 'steps',\n",
       " 'save_total_limit': 1,\n",
       " 'save_strategy': 'steps',\n",
       " 'save_steps': 100,\n",
       " 'seed': 42,\n",
       " 'logging_strategy': 'steps',\n",
       " 'report_to': 'tensorboard',\n",
       " 'mlm': False,\n",
       " 'truncation': True,\n",
       " 'padding': 'max_length',\n",
       " 'config_use_cache': False,\n",
       " 'resume_from_checkpoint': False,\n",
       " 'bleu_batch_size': 5,\n",
       " 'GRADIENT_ACCUMULATION_STEPS': 5,\n",
       " 'log_bleu_steps_factor': 50,\n",
       " 'load_best_model_at_end': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_config\n",
    "# {'experiment_name': 't2c_concode_220428_v19',\n",
    "#  'fn_train_dataset': '/root/data/t2c_train.json',\n",
    "#  'fn_eval_dataset': '/root/data/t2c_answers.json',\n",
    "#  'default_model': 'decapoda-research/llama-7b-hf',\n",
    "#  'MICRO_BATCH_SIZE': 2,\n",
    "#  'BATCH_SIZE': 10,\n",
    "#  'EPOCHS': 2,\n",
    "#  'LEARNING_RATE': 0.0002,\n",
    "#  'CUTOFF_LEN': 256,\n",
    "#  'LORA_R': 16,\n",
    "#  'LORA_ALPHA': 16,\n",
    "#  'LORA_DROPOUT': 0.05,\n",
    "#  'warmup_steps': 200,\n",
    "#  'fp16': True,\n",
    "#  'logging_steps': 10,\n",
    "#  'eval_steps': 100,\n",
    "#  'evaluation_strategy': 'steps',\n",
    "#  'save_total_limit': 1,\n",
    "#  'save_strategy': 'steps',\n",
    "#  'save_steps': 500,\n",
    "#  'seed': 42,\n",
    "#  'logging_strategy': 'steps',\n",
    "#  'report_to': 'tensorboard',\n",
    "#  'mlm': False,\n",
    "#  'truncation': True,\n",
    "#  'padding': 'max_length',\n",
    "#  'config_use_cache': False,\n",
    "#  'resume_from_checkpoint': False,\n",
    "#  'bleu_batch_size': 5,\n",
    "#  'GRADIENT_ACCUMULATION_STEPS': 5,\n",
    "#  'log_bleu_steps_factor': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6708fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config[\"resume_from_checkpoint\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1229c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ipynb/prompter/templates/\n"
     ]
    }
   ],
   "source": [
    "from prompter import Prompter\n",
    "prompter = Prompter()\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    if \"input\" in data_point and data_point[\"input\"]:\n",
    "        return prompter.generate_prompt(instruction = data_point[\"instruction\"],\n",
    "                                        input = data_point[\"input\"],\n",
    "                                        label = data_point[\"output\"]\n",
    "                                       )\n",
    "    else:\n",
    "        return prompter.generate_prompt(instruction = data_point[\"instruction\"],\n",
    "                                        #input = None,\n",
    "                                        label = data_point[\"output\"]\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bc4af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config[\"resume_from_checkpoint\"] ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce5420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14901' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14901/20000 18:23:17 < 6:17:35, 0.23 it/s, Epoch 1.49/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.045600</td>\n",
       "      <td>1.145902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.998100</td>\n",
       "      <td>1.136443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.922300</td>\n",
       "      <td>1.142087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.994800</td>\n",
       "      <td>1.139181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.940100</td>\n",
       "      <td>1.141253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.019800</td>\n",
       "      <td>1.144103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.919600</td>\n",
       "      <td>1.136041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.973900</td>\n",
       "      <td>1.146860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.976600</td>\n",
       "      <td>1.144602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.974800</td>\n",
       "      <td>1.150033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.903900</td>\n",
       "      <td>1.148804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>1.143241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.849600</td>\n",
       "      <td>1.144796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.884300</td>\n",
       "      <td>1.146587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>1.143002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>1.146797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.914500</td>\n",
       "      <td>1.141523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.852100</td>\n",
       "      <td>1.150167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.941800</td>\n",
       "      <td>1.144552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.841900</td>\n",
       "      <td>1.149381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>1.141888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.855700</td>\n",
       "      <td>1.149930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.812300</td>\n",
       "      <td>1.149649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.858900</td>\n",
       "      <td>1.147574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.838600</td>\n",
       "      <td>1.148305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.902400</td>\n",
       "      <td>1.136572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.860900</td>\n",
       "      <td>1.137414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.911500</td>\n",
       "      <td>1.136966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.832300</td>\n",
       "      <td>1.135817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.781700</td>\n",
       "      <td>1.137049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.838500</td>\n",
       "      <td>1.135671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.754800</td>\n",
       "      <td>1.138877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.921400</td>\n",
       "      <td>1.129920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.720400</td>\n",
       "      <td>1.139041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.878500</td>\n",
       "      <td>1.133371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>1.140988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.812700</td>\n",
       "      <td>1.136566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.894500</td>\n",
       "      <td>1.128935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.819900</td>\n",
       "      <td>1.144792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.820100</td>\n",
       "      <td>1.124308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.737600</td>\n",
       "      <td>1.135072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.797800</td>\n",
       "      <td>1.126317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.881600</td>\n",
       "      <td>1.130306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.869500</td>\n",
       "      <td>1.136810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>1.126110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.853300</td>\n",
       "      <td>1.130828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.793700</td>\n",
       "      <td>1.124118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.808600</td>\n",
       "      <td>1.126593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.769300</td>\n",
       "      <td>1.126669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.752100</td>\n",
       "      <td>1.133120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.129310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.758100</td>\n",
       "      <td>1.126419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.859300</td>\n",
       "      <td>1.125268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.809100</td>\n",
       "      <td>1.126544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.772200</td>\n",
       "      <td>1.127164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.819800</td>\n",
       "      <td>1.128083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.759700</td>\n",
       "      <td>1.121255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.730400</td>\n",
       "      <td>1.126400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.786700</td>\n",
       "      <td>1.122091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.787000</td>\n",
       "      <td>1.123543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.745600</td>\n",
       "      <td>1.113905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.713900</td>\n",
       "      <td>1.115429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.824200</td>\n",
       "      <td>1.106197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.811300</td>\n",
       "      <td>1.103104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.819700</td>\n",
       "      <td>1.105917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.784200</td>\n",
       "      <td>1.107693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.765900</td>\n",
       "      <td>1.103240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.813600</td>\n",
       "      <td>1.098466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.804600</td>\n",
       "      <td>1.116984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.771400</td>\n",
       "      <td>1.108483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.748400</td>\n",
       "      <td>1.115578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>1.109614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.729900</td>\n",
       "      <td>1.113572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.722700</td>\n",
       "      <td>1.115846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.719600</td>\n",
       "      <td>1.120781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.744200</td>\n",
       "      <td>1.106754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.725100</td>\n",
       "      <td>1.117563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.779200</td>\n",
       "      <td>1.114125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.675700</td>\n",
       "      <td>1.116277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.759200</td>\n",
       "      <td>1.101903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.745500</td>\n",
       "      <td>1.104479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>1.105603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.681700</td>\n",
       "      <td>1.104932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.753500</td>\n",
       "      <td>1.106899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.679000</td>\n",
       "      <td>1.105756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.769500</td>\n",
       "      <td>1.113556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.750500</td>\n",
       "      <td>1.105524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.697300</td>\n",
       "      <td>1.105826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.703600</td>\n",
       "      <td>1.104013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.691900</td>\n",
       "      <td>1.095797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>1.095152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.739300</td>\n",
       "      <td>1.093427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.709100</td>\n",
       "      <td>1.098216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.762200</td>\n",
       "      <td>1.096027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.731900</td>\n",
       "      <td>1.099259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.804200</td>\n",
       "      <td>1.102202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.652200</td>\n",
       "      <td>1.091826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.705100</td>\n",
       "      <td>1.092747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>1.092241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.706100</td>\n",
       "      <td>1.091829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.622500</td>\n",
       "      <td>1.104696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.606100</td>\n",
       "      <td>1.119861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.566800</td>\n",
       "      <td>1.106189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>1.119688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.550900</td>\n",
       "      <td>1.109531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.623200</td>\n",
       "      <td>1.108948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.549200</td>\n",
       "      <td>1.109013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.632500</td>\n",
       "      <td>1.115578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.585100</td>\n",
       "      <td>1.127286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.598000</td>\n",
       "      <td>1.115629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>1.123460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.584400</td>\n",
       "      <td>1.110775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.638300</td>\n",
       "      <td>1.111657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.611400</td>\n",
       "      <td>1.112045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.549300</td>\n",
       "      <td>1.115026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.570500</td>\n",
       "      <td>1.118447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.659600</td>\n",
       "      <td>1.108082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.561400</td>\n",
       "      <td>1.108496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.578400</td>\n",
       "      <td>1.109844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.626300</td>\n",
       "      <td>1.105750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>1.111432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.501100</td>\n",
       "      <td>1.120609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>1.115573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.581500</td>\n",
       "      <td>1.113817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.602600</td>\n",
       "      <td>1.106725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.557000</td>\n",
       "      <td>1.114722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.621800</td>\n",
       "      <td>1.097614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.540300</td>\n",
       "      <td>1.104354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>0.553800</td>\n",
       "      <td>1.096952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.517100</td>\n",
       "      <td>1.111431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13100</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>1.095860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.521300</td>\n",
       "      <td>1.108097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>0.633300</td>\n",
       "      <td>1.101191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.560900</td>\n",
       "      <td>1.107435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.510500</td>\n",
       "      <td>1.095918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.550200</td>\n",
       "      <td>1.101595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13700</td>\n",
       "      <td>0.613600</td>\n",
       "      <td>1.091804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.540700</td>\n",
       "      <td>1.097057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13900</td>\n",
       "      <td>0.516300</td>\n",
       "      <td>1.100432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>1.094171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14100</td>\n",
       "      <td>0.582500</td>\n",
       "      <td>1.101916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.565800</td>\n",
       "      <td>1.096379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14300</td>\n",
       "      <td>0.609600</td>\n",
       "      <td>1.089187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.445500</td>\n",
       "      <td>1.092216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.604200</td>\n",
       "      <td>1.082046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.535700</td>\n",
       "      <td>1.089205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14700</td>\n",
       "      <td>0.502700</td>\n",
       "      <td>1.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>1.084133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1/13 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|███████████████████████████████████████████| 30/30 [01:53<00:00,  3.77s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 154961.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.0013435187939136826, 'brevity_penalty': 0.15932557073921538, 'ratio': 0.3525091799265606, 'translation_length': 288, 'reference_length': 817, 'precisions_0': 0.06228373702422145, 'precisions_1': 0.003861003861003861, 'precisions_2': 0.004310344827586207, 'precisions_3': 0.004878048780487805}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:49<00:00,  3.66s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 161319.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.23851543777322842, 'brevity_penalty': 0.6806236541219175, 'ratio': 0.7221542227662179, 'translation_length': 590, 'reference_length': 817, 'precisions_0': 0.5871404399323181, 'precisions_1': 0.40819964349376114, 'precisions_2': 0.2919020715630885, 'precisions_3': 0.2155688622754491}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:49<00:00,  3.65s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 154391.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21494035595524252, 'brevity_penalty': 0.7169210474750201, 'ratio': 0.7503059975520195, 'translation_length': 613, 'reference_length': 817, 'precisions_0': 0.5700325732899023, 'precisions_1': 0.3801369863013699, 'precisions_2': 0.23826714801444043, 'precisions_3': 0.15648854961832062}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:52<00:00,  3.75s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 175984.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 1.0, 'BLEU': 0.13458196012156662, 'brevity_penalty': 0.39218604101656773, 'ratio': 0.5165238678090576, 'translation_length': 422, 'reference_length': 817, 'precisions_0': 0.6122931442080378, 'precisions_1': 0.40966921119592875, 'precisions_2': 0.273972602739726, 'precisions_3': 0.20178041543026706}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.68s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 179499.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20306184082454565, 'brevity_penalty': 0.687000076489837, 'ratio': 0.7270501835985312, 'translation_length': 594, 'reference_length': 817, 'precisions_0': 0.5327731092436975, 'precisions_1': 0.34690265486725663, 'precisions_2': 0.24067164179104478, 'precisions_3': 0.17159763313609466}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:51<00:00,  3.72s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 171897.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1903519854200471, 'brevity_penalty': 0.610424011465169, 'ratio': 0.6695226438188494, 'translation_length': 547, 'reference_length': 817, 'precisions_0': 0.5748175182481752, 'precisions_1': 0.3783783783783784, 'precisions_2': 0.2520491803278688, 'precisions_3': 0.17248908296943233}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:54<00:00,  3.81s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 57614.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.24854332777457233, 'brevity_penalty': 0.7028238366018249, 'ratio': 0.7392900856793145, 'translation_length': 604, 'reference_length': 817, 'precisions_0': 0.6165289256198347, 'precisions_1': 0.42782608695652175, 'precisions_2': 0.28807339449541286, 'precisions_3': 0.2058252427184466}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:52<00:00,  3.74s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 53340.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.17683350350528607, 'brevity_penalty': 0.5648732856616829, 'ratio': 0.6364749082007344, 'translation_length': 520, 'reference_length': 817, 'precisions_0': 0.6065259117082533, 'precisions_1': 0.39307535641547864, 'precisions_2': 0.25162689804772237, 'precisions_3': 0.16009280742459397}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:54<00:00,  3.82s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 150693.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.18702946689231648, 'brevity_penalty': 0.6774254411055589, 'ratio': 0.7197062423500612, 'translation_length': 588, 'reference_length': 817, 'precisions_0': 0.5500848896434635, 'precisions_1': 0.35062611806797855, 'precisions_2': 0.21172022684310018, 'precisions_3': 0.14228456913827656}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:52<00:00,  3.74s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 168671.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21228319831546086, 'brevity_penalty': 0.6499738697156315, 'ratio': 0.6988984088127295, 'translation_length': 571, 'reference_length': 817, 'precisions_0': 0.5996503496503497, 'precisions_1': 0.4003690036900369, 'precisions_2': 0.265625, 'precisions_3': 0.17842323651452283}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:52<00:00,  3.77s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 155729.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.19954629584644717, 'brevity_penalty': 0.6368924160294538, 'ratio': 0.6891064871481029, 'translation_length': 563, 'reference_length': 817, 'precisions_0': 0.5372340425531915, 'precisions_1': 0.37265917602996257, 'precisions_2': 0.25742574257425743, 'precisions_3': 0.1869747899159664}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:53<00:00,  3.79s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 160291.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.19640169101586974, 'brevity_penalty': 0.6137544855680206, 'ratio': 0.6719706242350061, 'translation_length': 549, 'reference_length': 817, 'precisions_0': 0.5945454545454546, 'precisions_1': 0.40192307692307694, 'precisions_2': 0.25661914460285135, 'precisions_3': 0.170995670995671}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:55<00:00,  3.85s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 175249.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.17567476311810784, 'brevity_penalty': 0.5217821838472736, 'ratio': 0.605875152998776, 'translation_length': 495, 'reference_length': 817, 'precisions_0': 0.6048387096774194, 'precisions_1': 0.41201716738197425, 'precisions_2': 0.271689497716895, 'precisions_3': 0.1897810218978102}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:57<00:00,  3.91s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 190361.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.12944376896430534, 'brevity_penalty': 0.41913374169932255, 'ratio': 0.5348837209302325, 'translation_length': 437, 'reference_length': 817, 'precisions_0': 0.589041095890411, 'precisions_1': 0.3897058823529412, 'precisions_2': 0.24473684210526317, 'precisions_3': 0.16193181818181818}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:54<00:00,  3.83s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 48865.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1757243732711967, 'brevity_penalty': 0.5699871333971371, 'ratio': 0.6401468788249693, 'translation_length': 523, 'reference_length': 817, 'precisions_0': 0.6030534351145038, 'precisions_1': 0.3785425101214575, 'precisions_2': 0.24301075268817204, 'precisions_3': 0.1628440366972477}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:59<00:00,  3.97s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 177224.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.17170413414745034, 'brevity_penalty': 0.6467131914862885, 'ratio': 0.6964504283965728, 'translation_length': 569, 'reference_length': 817, 'precisions_0': 0.5298245614035088, 'precisions_1': 0.3333333333333333, 'precisions_2': 0.2054794520547945, 'precisions_3': 0.13692946058091288}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:56<00:00,  3.87s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 45689.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2256022436330819, 'brevity_penalty': 0.6286644024420278, 'ratio': 0.6829865361077111, 'translation_length': 558, 'reference_length': 817, 'precisions_0': 0.629695885509839, 'precisions_1': 0.42911153119092627, 'precisions_2': 0.292, 'precisions_3': 0.21019108280254778}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:56<00:00,  3.87s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 163840.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.19324057134258196, 'brevity_penalty': 0.6286644024420278, 'ratio': 0.6829865361077111, 'translation_length': 558, 'reference_length': 817, 'precisions_0': 0.6100178890876565, 'precisions_1': 0.3837429111531191, 'precisions_2': 0.23847695390781562, 'precisions_3': 0.15991471215351813}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:52<00:00,  3.77s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 181571.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 1.0, 'BLEU': 0.18559113158956903, 'brevity_penalty': 0.5511748847488191, 'ratio': 0.6266829865361077, 'translation_length': 512, 'reference_length': 817, 'precisions_0': 0.6140350877192983, 'precisions_1': 0.40993788819875776, 'precisions_2': 0.26593406593406593, 'precisions_3': 0.1920374707259953}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:53<00:00,  3.79s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 169809.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20369330460741855, 'brevity_penalty': 0.57678561653526, 'ratio': 0.6450428396572827, 'translation_length': 527, 'reference_length': 817, 'precisions_0': 0.6098484848484849, 'precisions_1': 0.42971887550200805, 'precisions_2': 0.29148936170212764, 'precisions_3': 0.20361990950226244}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:53<00:00,  3.77s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 56048.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21003710061481629, 'brevity_penalty': 0.6385332304644112, 'ratio': 0.6903304773561811, 'translation_length': 564, 'reference_length': 817, 'precisions_0': 0.6053097345132743, 'precisions_1': 0.40186915887850466, 'precisions_2': 0.2608695652173913, 'precisions_3': 0.18448637316561844}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:52<00:00,  3.76s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 171429.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20489339684450852, 'brevity_penalty': 0.6385332304644112, 'ratio': 0.6903304773561811, 'translation_length': 564, 'reference_length': 817, 'precisions_0': 0.5699115044247788, 'precisions_1': 0.38317757009345793, 'precisions_2': 0.2583826429980276, 'precisions_3': 0.18789144050104384}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:52<00:00,  3.74s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 173318.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.23567893412121688, 'brevity_penalty': 0.6854084757090199, 'ratio': 0.7258261933904528, 'translation_length': 593, 'reference_length': 817, 'precisions_0': 0.5909090909090909, 'precisions_1': 0.39893617021276595, 'precisions_2': 0.2846441947565543, 'precisions_3': 0.20833333333333334}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:53<00:00,  3.79s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 182625.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.19609105912525493, 'brevity_penalty': 0.6434460411594718, 'ratio': 0.6940024479804161, 'translation_length': 567, 'reference_length': 817, 'precisions_0': 0.5616197183098591, 'precisions_1': 0.36617100371747213, 'precisions_2': 0.24803149606299213, 'precisions_3': 0.16910229645093947}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:54<00:00,  3.82s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 170500.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.22401215160845195, 'brevity_penalty': 0.7370409530635013, 'ratio': 0.7662178702570379, 'translation_length': 626, 'reference_length': 817, 'precisions_0': 0.5885167464114832, 'precisions_1': 0.38190954773869346, 'precisions_2': 0.23985890652557318, 'precisions_3': 0.15828677839851024}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:52<00:00,  3.73s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 176974.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.19411240537125776, 'brevity_penalty': 0.6516017749168791, 'ratio': 0.7001223990208079, 'translation_length': 572, 'reference_length': 817, 'precisions_0': 0.5828970331588132, 'precisions_1': 0.3701657458563536, 'precisions_2': 0.23196881091617932, 'precisions_3': 0.15734989648033126}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:53<00:00,  3.78s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 166220.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20887726361762649, 'brevity_penalty': 0.6154173979975659, 'ratio': 0.6731946144430845, 'translation_length': 550, 'reference_length': 817, 'precisions_0': 0.6243194192377496, 'precisions_1': 0.4049904030710173, 'precisions_2': 0.26883910386965376, 'precisions_3': 0.19522776572668113}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:53<00:00,  3.79s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 166661.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20810765110373305, 'brevity_penalty': 0.600395689520306, 'ratio': 0.6621787025703795, 'translation_length': 541, 'reference_length': 817, 'precisions_0': 0.6512915129151291, 'precisions_1': 0.419921875, 'precisions_2': 0.27800829875518673, 'precisions_3': 0.18984547461368653}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:52<00:00,  3.75s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 178734.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20930508715155097, 'brevity_penalty': 0.5750881536940058, 'ratio': 0.6438188494492044, 'translation_length': 526, 'reference_length': 817, 'precisions_0': 0.6489563567362429, 'precisions_1': 0.4346076458752515, 'precisions_2': 0.2955032119914347, 'precisions_3': 0.21052631578947367}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:56<00:00,  3.88s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 170500.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.1998370775399134, 'brevity_penalty': 0.558035145770047, 'ratio': 0.631578947368421, 'translation_length': 516, 'reference_length': 817, 'precisions_0': 0.6247582205029013, 'precisions_1': 0.41683778234086244, 'precisions_2': 0.28820960698689957, 'precisions_3': 0.2191142191142191}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:52<00:00,  3.75s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 51337.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.22227337156898896, 'brevity_penalty': 0.63196038331477, 'ratio': 0.6854345165238678, 'translation_length': 560, 'reference_length': 817, 'precisions_0': 0.6149732620320856, 'precisions_1': 0.4218455743879473, 'precisions_2': 0.2894211576846307, 'precisions_3': 0.20382165605095542}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:52<00:00,  3.74s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 53934.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2009365018689266, 'brevity_penalty': 0.6385332304644112, 'ratio': 0.6903304773561811, 'translation_length': 564, 'reference_length': 817, 'precisions_0': 0.5876106194690266, 'precisions_1': 0.3775700934579439, 'precisions_2': 0.2509881422924901, 'precisions_3': 0.1761006289308176}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:51<00:00,  3.73s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 180013.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21060673693233478, 'brevity_penalty': 0.7523217443777271, 'ratio': 0.7784577723378213, 'translation_length': 636, 'reference_length': 817, 'precisions_0': 0.5400313971742543, 'precisions_1': 0.34596375617792424, 'precisions_2': 0.21663778162911612, 'precisions_3': 0.15173674588665448}\n"
     ]
    }
   ],
   "source": [
    "# def generate_prompt(data_point):\n",
    "#     # sorry about the formatting disaster gotta move fast\n",
    "#     if data_point[\"input\"]:\n",
    "#         return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "# ### Instruction:\n",
    "# {data_point[\"instruction\"]}\n",
    "# ### Input:\n",
    "# {data_point[\"input\"]}\n",
    "# ### Response:\n",
    "# {data_point[\"output\"]}\"\"\"\n",
    "#     else:\n",
    "#         return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "# ### Instruction:\n",
    "# {data_point[\"instruction\"]}\n",
    "# ### Response:\n",
    "# {data_point[\"output\"]}\"\"\"\n",
    "\n",
    "\n",
    "data = data.shuffle().map(\n",
    "    lambda data_point: tokenizer(\n",
    "        generate_prompt(data_point),\n",
    "        truncation=experiment_config[\"truncation\"],\n",
    "        max_length=experiment_config[\"CUTOFF_LEN\"],\n",
    "        padding=experiment_config[\"padding\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer_val,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data['eval'],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=experiment_config[\"MICRO_BATCH_SIZE\"],\n",
    "        gradient_accumulation_steps=experiment_config[\"GRADIENT_ACCUMULATION_STEPS\"],\n",
    "        warmup_steps=experiment_config[\"warmup_steps\"],\n",
    "        num_train_epochs=experiment_config[\"EPOCHS\"],\n",
    "        learning_rate=experiment_config[\"LEARNING_RATE\"],\n",
    "        fp16=experiment_config[\"fp16\"],\n",
    "        logging_steps=experiment_config[\"logging_steps\"],        \n",
    "        evaluation_strategy = experiment_config['evaluation_strategy'],\n",
    "        eval_steps=experiment_config[\"eval_steps\"],\n",
    "        output_dir=current_experiment_path,#\"lora-alpaca\",\n",
    "        save_total_limit=experiment_config[\"save_total_limit\"],\n",
    "        save_strategy = experiment_config[\"save_strategy\"],\n",
    "        \n",
    "        save_steps = experiment_config[\"save_steps\"],\n",
    "        seed=experiment_config[\"seed\"],\n",
    "        logging_dir=current_experiment_path,\n",
    "        logging_strategy=experiment_config[\"logging_strategy\"],\n",
    "        report_to=experiment_config[\"report_to\"],\n",
    "        load_best_model_at_end = experiment_config[\"load_best_model_at_end\"]\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, \n",
    "                                                               mlm=experiment_config[\"mlm\"]\n",
    "                                                              ),\n",
    "    callbacks = [MyCustomCallback]\n",
    ")\n",
    "model.config.use_cache = experiment_config[\"config_use_cache\"]\n",
    "# print(len(trainer.optimizer.state['found_inf_per_device']))\n",
    "\n",
    "\n",
    "trainer.train(resume_from_checkpoint=experiment_config[\"resume_from_checkpoint\"])\n",
    "\n",
    "model.save_pretrained(current_experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97522ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/experiments/t2c_concode_220428_v31'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_experiment_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d9aa6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1684072293.7154148   checkpoint-20000\r\n",
      "1684072293.727496    events.out.tfevents.1684072293.8d048d63ed1a.18071.0\r\n",
      "adapter_config.json  events.out.tfevents.1684072293.8d048d63ed1a.18071.2\r\n",
      "adapter_model.bin    experiment_config.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa33d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa25528",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "839d4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(current_experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac663873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 't2c_concode_220428_v22',\n",
       " 'fn_train_dataset': '/root/data/t2c_train.json',\n",
       " 'fn_eval_dataset': '/root/data/t2c_answers.json',\n",
       " 'default_model': 'decapoda-research/llama-7b-hf',\n",
       " 'MICRO_BATCH_SIZE': 2,\n",
       " 'BATCH_SIZE': 10,\n",
       " 'EPOCHS': 2,\n",
       " 'LEARNING_RATE': 0.0002,\n",
       " 'CUTOFF_LEN': 256,\n",
       " 'LORA_R': 64,\n",
       " 'LORA_ALPHA': 64,\n",
       " 'LORA_DROPOUT': 0.05,\n",
       " 'warmup_steps': 200,\n",
       " 'fp16': True,\n",
       " 'logging_steps': 10,\n",
       " 'eval_steps': 100,\n",
       " 'evaluation_strategy': 'steps',\n",
       " 'save_total_limit': 1,\n",
       " 'save_strategy': 'steps',\n",
       " 'save_steps': 500,\n",
       " 'seed': 42,\n",
       " 'logging_strategy': 'steps',\n",
       " 'report_to': 'tensorboard',\n",
       " 'mlm': False,\n",
       " 'truncation': True,\n",
       " 'padding': 'max_length',\n",
       " 'config_use_cache': False,\n",
       " 'resume_from_checkpoint': False,\n",
       " 'bleu_batch_size': 5,\n",
       " 'GRADIENT_ACCUMULATION_STEPS': 5,\n",
       " 'log_bleu_steps_factor': 50}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "665c1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(current_experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e72383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fe786fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2c_concode_220428_v12\tt2c_concode_220428_v16\tt2c_concode_220428_v22\r\n",
      "t2c_concode_220428_v13\tt2c_concode_220428_v18\tt2c_concode_220428_v30\r\n",
      "t2c_concode_220428_v14\tt2c_concode_220428_v19\tt2c_concode_220428_v9\r\n",
      "t2c_concode_220428_v15\tt2c_concode_220428_v20\r\n"
     ]
    }
   ],
   "source": [
    "!ls /root/experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "220a459f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14G\t/root/\r\n"
     ]
    }
   ],
   "source": [
    "# !du -hs /root/ | sort -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "97e5c6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13G\t/root/.cache/huggingface/hub\r\n"
     ]
    }
   ],
   "source": [
    "# !du -lahS /root/\n",
    "# !du -hs /root/.cache/huggingface/* | sort -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8940a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /root/.cache/huggingface/hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68a3752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls /root/experiments/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a8f14bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay          45G   17G   29G  37% /\r\n"
     ]
    }
   ],
   "source": [
    "!df -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_experiment_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d411735",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah /root/experiments/t2c_concode_220428_v20/checkpoint-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah /root/experiments/t2c_concode_220428_v20/checkpoint-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dca9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /root/experiments/t2c_concode_220428_v19/checkpoint-20000/\n",
    "# !df -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97279e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf {current_experiment_path}/checkpoint-1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feedd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a22c54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay          45G   45G  3.6M 100% /\r\n"
     ]
    }
   ],
   "source": [
    "!df -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "731023f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1683303090.6023178   adapter_model.bin\r\n",
      "1683303090.6101534   events.out.tfevents.1683303090.8d048d63ed1a.5752.0\r\n",
      "1683303146.4560587   events.out.tfevents.1683303090.8d048d63ed1a.5752.2\r\n",
      "1683303146.4694548   events.out.tfevents.1683303146.8d048d63ed1a.5752.4\r\n",
      "1683303388.633225    events.out.tfevents.1683303146.8d048d63ed1a.5752.6\r\n",
      "1683303388.645383    events.out.tfevents.1683303388.8d048d63ed1a.5752.10\r\n",
      "1683303483.1163416   events.out.tfevents.1683303388.8d048d63ed1a.5752.8\r\n",
      "1683303483.1291792   events.out.tfevents.1683303483.8d048d63ed1a.5752.12\r\n",
      "1683303652.147785    events.out.tfevents.1683303483.8d048d63ed1a.5752.14\r\n",
      "1683303652.1612782   events.out.tfevents.1683303652.8d048d63ed1a.5752.16\r\n",
      "1683303676.8182936   events.out.tfevents.1683303652.8d048d63ed1a.5752.18\r\n",
      "1683303676.8320808   events.out.tfevents.1683303676.8d048d63ed1a.5752.20\r\n",
      "1683303700.7354565   events.out.tfevents.1683303676.8d048d63ed1a.5752.22\r\n",
      "1683303700.7492273   events.out.tfevents.1683303700.8d048d63ed1a.5752.24\r\n",
      "1683303738.1971772   events.out.tfevents.1683303700.8d048d63ed1a.5752.26\r\n",
      "1683303738.208674    events.out.tfevents.1683303738.8d048d63ed1a.5752.28\r\n",
      "1683304244.2201474   events.out.tfevents.1683303738.8d048d63ed1a.5752.30\r\n",
      "1683304244.2324886   events.out.tfevents.1683304244.8d048d63ed1a.6142.0\r\n",
      "1683304469.9929264   events.out.tfevents.1683304244.8d048d63ed1a.6142.2\r\n",
      "1683304470.0023499   events.out.tfevents.1683304469.8d048d63ed1a.6142.4\r\n",
      "1683305248.9343088   events.out.tfevents.1683304469.8d048d63ed1a.6142.6\r\n",
      "1683305248.9410791   events.out.tfevents.1683305248.8d048d63ed1a.6275.0\r\n",
      "1683305916.0134802   events.out.tfevents.1683305248.8d048d63ed1a.6275.2\r\n",
      "1683305916.023698    events.out.tfevents.1683305916.8d048d63ed1a.6427.0\r\n",
      "1683306963.8205214   events.out.tfevents.1683305916.8d048d63ed1a.6427.2\r\n",
      "1683306963.8250442   events.out.tfevents.1683306963.8d048d63ed1a.6747.0\r\n",
      "adapter_config.json  events.out.tfevents.1683306963.8d048d63ed1a.6747.2\r\n"
     ]
    }
   ],
   "source": [
    "!ls /root/experiments/t2c_concode_220428_v13/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dccce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay          45G   24G   22G  54% /\r\n"
     ]
    }
   ],
   "source": [
    "!df -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07e61405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "overlay          45G   24G   22G  54% /\r\n"
     ]
    }
   ],
   "source": [
    "!df -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa1098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
