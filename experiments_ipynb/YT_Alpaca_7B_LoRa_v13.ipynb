{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ac0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All to folder\n",
    "## generate prompt\n",
    "# !ls data\n",
    "# import time\n",
    "# time.sleep(60*30)\n",
    "\n",
    "# Try to do:\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c4ccf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import transformers\n",
    "from peft import PeftModel\n",
    "from transformers import LlamaForCausalLM as LLaMAForCausalLM\n",
    "from transformers import LlamaTokenizer as LLaMATokenizer\n",
    "from peft import prepare_model_for_int8_training, LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "from EvaluateTestSet import EvaluateTestSet\n",
    "from transformers.integrations import TensorBoardCallback\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "def init_lora_model_and_tokenizer(default_model,\n",
    "                             LORA_R,\n",
    "                             LORA_ALPHA,\n",
    "                             LORA_DROPOUT\n",
    "                            ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    \"\"\"\n",
    "    model = LLaMAForCausalLM.from_pretrained(\n",
    "    default_model,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    )\n",
    "    tokenizer = LLaMATokenizer.from_pretrained(\n",
    "        default_model, add_eos_token=True\n",
    "    )\n",
    "\n",
    "    model = prepare_model_for_int8_training(model)\n",
    "\n",
    "    config = LoraConfig(\n",
    "        r=LORA_R,\n",
    "        lora_alpha=LORA_ALPHA,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        lora_dropout=LORA_DROPOUT,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    model = get_peft_model(model, config)\n",
    "\n",
    "    tokenizer.pad_token_id = 0  # unk. we want this to be different from the eos token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "class MyCustomCallback(TensorBoardCallback):\n",
    "    #log_bleu_steps_factor = 5\n",
    "    bleu_generation_max_new_tokens = 30\n",
    "    bleu_fn_test_data = \"temp/t2c_answers.json\"\n",
    "    bleu_fn_etalon = \"temp/answers.json\"\n",
    "    log_step = 0\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        super().on_log(args, state, control, logs=logs, **kwargs)\n",
    "        #print(\"kwargs\", len(kwargs), kwargs.keys())\n",
    "        if self.tb_writer is not None:\n",
    "            #print(state)\n",
    "            #print(state.global_step)\n",
    "            #print(self.log_step)\n",
    "            if (self.log_step % self.log_bleu_steps_factor ==0):\n",
    "                model = kwargs['model']\n",
    "                tokenizer = kwargs['tokenizer']\n",
    "                \n",
    "                model.eval()\n",
    "                assert not model.training\n",
    "                generation_config = GenerationConfig(max_new_tokens = self.bleu_generation_max_new_tokens,\n",
    "                                                     # min_new_tokens = 5,\n",
    "                                                     temperature = 1.0\n",
    "                                                    )\n",
    "                print(\"generation_config:\", generation_config)\n",
    "                evaluator = EvaluateTestSet(generation_config = generation_config,\n",
    "                                            fn_test_data = self.bleu_fn_test_data,\n",
    "                                            fn_etalon = self.bleu_fn_etalon,\n",
    "                                            batch_size = 1\n",
    "                                       )\n",
    "\n",
    "                metric_res = evaluator.evaluate(model=model, \n",
    "                                                tokenizer=tokenizer,\n",
    "                                               )\n",
    "                model.train()\n",
    "                assert model.training\n",
    "                print(metric_res)\n",
    "                for key, val in metric_res.items():\n",
    "                    #add \"custom/something\"\n",
    "                    self.tb_writer.add_scalar(key, val, state.global_step)\n",
    "                self.tb_writer.flush()\n",
    "            self.log_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a58e71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = \"/root/experiments_configs/\"\n",
    "EXPERIMENTS_PATH = \"/root/experiments/\"\n",
    "experiment_name = \"t2c_concode_220428_v22\"\n",
    "# t2c_concode_220428_v18.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51baf7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t2c_concode_220428_v14_config.json  t2c_concode_220428_v18_config.json\r\n",
      "t2c_concode_220428_v15_config.json  t2c_concode_220428_v19_config.json\r\n",
      "t2c_concode_220428_v16_config.json  t2c_concode_220428_v20_config.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls /root/experiments_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc88f56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_config_path = os.path.join(CONFIG_PATH, experiment_name + \"_config.json\")\n",
    "experiment_config = json.load(open(current_config_path, \"r\"))\n",
    "\n",
    "assert experiment_config['experiment_name'] == experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6eff1d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config['resume_from_checkpoint'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50bb0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert experiment_config['resume_from_checkpoint'] == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dc63c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert experiment_config['experiment_name'] == experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f52cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_experiment_path = os.path.join(EXPERIMENTS_PATH, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acf204b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/root/experiments/t2c_concode_220428_v22’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d7a3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(experiment_config, open(current_experiment_path + \\\n",
    "                                  \"/experiment_config.json\", \n",
    "                                  \"w+\"\n",
    "                                 )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "946d5e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(MyCustomCallback, \"log_bleu_steps_factor\", experiment_config['log_bleu_steps_factor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e33b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyCustomCallback.log_bleu_steps_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e5bab5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b88a8088364346815706cdd7fa1787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n",
      "Found cached dataset json (/root/.cache/huggingface/datasets/json/default-3ac2744fedc77f2f/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc87ebf99f147498b09564cf3651c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, tokenizer = init_lora_model_and_tokenizer(default_model = experiment_config[\"default_model\"],\n",
    "                                                 LORA_R = experiment_config[\"LORA_R\"],\n",
    "                                                 LORA_ALPHA = experiment_config[\"LORA_ALPHA\"],\n",
    "                                                 LORA_DROPOUT = experiment_config[\"LORA_DROPOUT\"]\n",
    "                                                )\n",
    "\n",
    "\n",
    "data = load_dataset(\"json\", \n",
    "                    data_files = {\"train\": experiment_config[\"fn_train_dataset\"],\n",
    "                                  \"eval\":  experiment_config[\"fn_eval_dataset\"]\n",
    "                                 }\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e83f74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_val = LLaMATokenizer.from_pretrained(\n",
    "    experiment_config['default_model'], add_eos_token=True\n",
    ")\n",
    "tokenizer_val.pad_token_id = 0  # unk. we want this to be different from the eos token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a58aea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config[\"logging_steps\"] = 1\n",
    "# experiment_config[\"eval_steps\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "415d4e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 't2c_concode_220428_v22',\n",
       " 'fn_train_dataset': '/root/data/t2c_train.json',\n",
       " 'fn_eval_dataset': '/root/data/t2c_answers.json',\n",
       " 'default_model': 'decapoda-research/llama-7b-hf',\n",
       " 'MICRO_BATCH_SIZE': 2,\n",
       " 'BATCH_SIZE': 10,\n",
       " 'EPOCHS': 2,\n",
       " 'LEARNING_RATE': 0.0002,\n",
       " 'CUTOFF_LEN': 256,\n",
       " 'LORA_R': 64,\n",
       " 'LORA_ALPHA': 64,\n",
       " 'LORA_DROPOUT': 0.05,\n",
       " 'warmup_steps': 200,\n",
       " 'fp16': True,\n",
       " 'logging_steps': 10,\n",
       " 'eval_steps': 100,\n",
       " 'evaluation_strategy': 'steps',\n",
       " 'save_total_limit': 1,\n",
       " 'save_strategy': 'steps',\n",
       " 'save_steps': 500,\n",
       " 'seed': 42,\n",
       " 'logging_strategy': 'steps',\n",
       " 'report_to': 'tensorboard',\n",
       " 'mlm': False,\n",
       " 'truncation': True,\n",
       " 'padding': 'max_length',\n",
       " 'config_use_cache': False,\n",
       " 'resume_from_checkpoint': True,\n",
       " 'bleu_batch_size': 5,\n",
       " 'GRADIENT_ACCUMULATION_STEPS': 5,\n",
       " 'log_bleu_steps_factor': 50}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_config\n",
    "# {'experiment_name': 't2c_concode_220428_v19',\n",
    "#  'fn_train_dataset': '/root/data/t2c_train.json',\n",
    "#  'fn_eval_dataset': '/root/data/t2c_answers.json',\n",
    "#  'default_model': 'decapoda-research/llama-7b-hf',\n",
    "#  'MICRO_BATCH_SIZE': 2,\n",
    "#  'BATCH_SIZE': 10,\n",
    "#  'EPOCHS': 2,\n",
    "#  'LEARNING_RATE': 0.0002,\n",
    "#  'CUTOFF_LEN': 256,\n",
    "#  'LORA_R': 16,\n",
    "#  'LORA_ALPHA': 16,\n",
    "#  'LORA_DROPOUT': 0.05,\n",
    "#  'warmup_steps': 200,\n",
    "#  'fp16': True,\n",
    "#  'logging_steps': 10,\n",
    "#  'eval_steps': 100,\n",
    "#  'evaluation_strategy': 'steps',\n",
    "#  'save_total_limit': 1,\n",
    "#  'save_strategy': 'steps',\n",
    "#  'save_steps': 500,\n",
    "#  'seed': 42,\n",
    "#  'logging_strategy': 'steps',\n",
    "#  'report_to': 'tensorboard',\n",
    "#  'mlm': False,\n",
    "#  'truncation': True,\n",
    "#  'padding': 'max_length',\n",
    "#  'config_use_cache': False,\n",
    "#  'resume_from_checkpoint': False,\n",
    "#  'bleu_batch_size': 5,\n",
    "#  'GRADIENT_ACCUMULATION_STEPS': 5,\n",
    "#  'log_bleu_steps_factor': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6708fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config[\"resume_from_checkpoint\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1229c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/ipynb/prompter/templates/\n"
     ]
    }
   ],
   "source": [
    "from prompter import Prompter\n",
    "prompter = Prompter()\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    if \"input\" in data_point and data_point[\"input\"]:\n",
    "        return prompter.generate_prompt(instruction = data_point[\"instruction\"],\n",
    "                                        input = data_point[\"input\"],\n",
    "                                        label = data_point[\"output\"]\n",
    "                                       )\n",
    "    else:\n",
    "        return prompter.generate_prompt(instruction = data_point[\"instruction\"],\n",
    "                                        #input = None,\n",
    "                                        label = data_point[\"output\"]\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bc4af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_config[\"resume_from_checkpoint\"] ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dce5420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20000' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20000/20000 22:57:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.098500</td>\n",
       "      <td>1.200303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.038000</td>\n",
       "      <td>1.140061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.987900</td>\n",
       "      <td>1.125297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.998800</td>\n",
       "      <td>1.120366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.947300</td>\n",
       "      <td>1.112980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>1.113665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.927700</td>\n",
       "      <td>1.108950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.953000</td>\n",
       "      <td>1.108034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.941400</td>\n",
       "      <td>1.107022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.943200</td>\n",
       "      <td>1.105373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.968500</td>\n",
       "      <td>1.105251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.920600</td>\n",
       "      <td>1.103682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.910800</td>\n",
       "      <td>1.101036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.929100</td>\n",
       "      <td>1.102324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.907800</td>\n",
       "      <td>1.099619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.922000</td>\n",
       "      <td>1.097786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.913700</td>\n",
       "      <td>1.098935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.908300</td>\n",
       "      <td>1.095687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.883700</td>\n",
       "      <td>1.096256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.884500</td>\n",
       "      <td>1.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.821500</td>\n",
       "      <td>1.094001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.789500</td>\n",
       "      <td>1.095343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.842900</td>\n",
       "      <td>1.094994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.870200</td>\n",
       "      <td>1.096343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.835300</td>\n",
       "      <td>1.092362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.836500</td>\n",
       "      <td>1.090482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.842400</td>\n",
       "      <td>1.094250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.891300</td>\n",
       "      <td>1.095843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.837300</td>\n",
       "      <td>1.089869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.916400</td>\n",
       "      <td>1.089799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.929400</td>\n",
       "      <td>1.086589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>1.090700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.886900</td>\n",
       "      <td>1.088805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.816800</td>\n",
       "      <td>1.089280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.831300</td>\n",
       "      <td>1.084054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.877100</td>\n",
       "      <td>1.088892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.828800</td>\n",
       "      <td>1.086139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>1.086980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.836300</td>\n",
       "      <td>1.088507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.868200</td>\n",
       "      <td>1.087602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.810100</td>\n",
       "      <td>1.082652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.859800</td>\n",
       "      <td>1.084118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.863500</td>\n",
       "      <td>1.086541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.863000</td>\n",
       "      <td>1.087489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.789100</td>\n",
       "      <td>1.083688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>1.082673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.831700</td>\n",
       "      <td>1.078836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>1.085065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.788400</td>\n",
       "      <td>1.082519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.845900</td>\n",
       "      <td>1.081335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.767700</td>\n",
       "      <td>1.083743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.856200</td>\n",
       "      <td>1.085956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.794100</td>\n",
       "      <td>1.083406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>1.080466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.709500</td>\n",
       "      <td>1.085093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.791500</td>\n",
       "      <td>1.076140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.787300</td>\n",
       "      <td>1.076735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.751200</td>\n",
       "      <td>1.077058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.782300</td>\n",
       "      <td>1.077458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.770300</td>\n",
       "      <td>1.081709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>1.079930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.789300</td>\n",
       "      <td>1.078842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.815400</td>\n",
       "      <td>1.076328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.817800</td>\n",
       "      <td>1.079908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>1.075479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.749300</td>\n",
       "      <td>1.078246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>1.075240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.774100</td>\n",
       "      <td>1.070169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>1.073822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.830300</td>\n",
       "      <td>1.073806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.802200</td>\n",
       "      <td>1.073994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.820600</td>\n",
       "      <td>1.076263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.725100</td>\n",
       "      <td>1.084222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.783400</td>\n",
       "      <td>1.076092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.774300</td>\n",
       "      <td>1.076319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.788200</td>\n",
       "      <td>1.075601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.729500</td>\n",
       "      <td>1.074474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.807300</td>\n",
       "      <td>1.074046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.682500</td>\n",
       "      <td>1.074469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.820800</td>\n",
       "      <td>1.075064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.664700</td>\n",
       "      <td>1.071918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.785300</td>\n",
       "      <td>1.070657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.797700</td>\n",
       "      <td>1.073799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.793100</td>\n",
       "      <td>1.070312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.745800</td>\n",
       "      <td>1.073038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.750300</td>\n",
       "      <td>1.068965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.764600</td>\n",
       "      <td>1.072841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.764400</td>\n",
       "      <td>1.068501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.760900</td>\n",
       "      <td>1.069262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.717100</td>\n",
       "      <td>1.069182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>1.069648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.724900</td>\n",
       "      <td>1.066694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.733800</td>\n",
       "      <td>1.071218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.714800</td>\n",
       "      <td>1.066277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.722000</td>\n",
       "      <td>1.070180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>1.067799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.761400</td>\n",
       "      <td>1.067734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.675900</td>\n",
       "      <td>1.064244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.766800</td>\n",
       "      <td>1.062891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.704200</td>\n",
       "      <td>1.064469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.708100</td>\n",
       "      <td>1.069579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.664600</td>\n",
       "      <td>1.070877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.702400</td>\n",
       "      <td>1.073165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.750200</td>\n",
       "      <td>1.074205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>1.074245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.750200</td>\n",
       "      <td>1.072589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.700400</td>\n",
       "      <td>1.075518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.683500</td>\n",
       "      <td>1.075911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10900</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>1.072530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.698000</td>\n",
       "      <td>1.075992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11100</td>\n",
       "      <td>0.711300</td>\n",
       "      <td>1.074054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.758100</td>\n",
       "      <td>1.077479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11300</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>1.078416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.673800</td>\n",
       "      <td>1.077091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.653200</td>\n",
       "      <td>1.078066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.643300</td>\n",
       "      <td>1.078893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11700</td>\n",
       "      <td>0.738900</td>\n",
       "      <td>1.071846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.792200</td>\n",
       "      <td>1.075424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11900</td>\n",
       "      <td>0.788300</td>\n",
       "      <td>1.073019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.671200</td>\n",
       "      <td>1.074076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12100</td>\n",
       "      <td>0.679300</td>\n",
       "      <td>1.072547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>1.071444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12300</td>\n",
       "      <td>0.625600</td>\n",
       "      <td>1.070420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>1.075471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.651100</td>\n",
       "      <td>1.081710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.599800</td>\n",
       "      <td>1.079669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12700</td>\n",
       "      <td>0.726400</td>\n",
       "      <td>1.078555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.791600</td>\n",
       "      <td>1.070607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12900</td>\n",
       "      <td>0.601900</td>\n",
       "      <td>1.072471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.702500</td>\n",
       "      <td>1.072112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13100</td>\n",
       "      <td>0.686200</td>\n",
       "      <td>1.072968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.645600</td>\n",
       "      <td>1.075478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13300</td>\n",
       "      <td>0.664700</td>\n",
       "      <td>1.065032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.667200</td>\n",
       "      <td>1.071352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.709600</td>\n",
       "      <td>1.067934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.749200</td>\n",
       "      <td>1.071047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13700</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>1.075086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.581600</td>\n",
       "      <td>1.068158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13900</td>\n",
       "      <td>0.729700</td>\n",
       "      <td>1.069917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.639100</td>\n",
       "      <td>1.068342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14100</td>\n",
       "      <td>0.663000</td>\n",
       "      <td>1.069833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>1.069978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14300</td>\n",
       "      <td>0.701200</td>\n",
       "      <td>1.068018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.618700</td>\n",
       "      <td>1.066630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.614500</td>\n",
       "      <td>1.069122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>1.069967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14700</td>\n",
       "      <td>0.613800</td>\n",
       "      <td>1.069460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.633200</td>\n",
       "      <td>1.071643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14900</td>\n",
       "      <td>0.633400</td>\n",
       "      <td>1.065806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>1.069224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15100</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>1.066510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.591400</td>\n",
       "      <td>1.065136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15300</td>\n",
       "      <td>0.688100</td>\n",
       "      <td>1.064936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.642900</td>\n",
       "      <td>1.068745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.694900</td>\n",
       "      <td>1.065793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.686400</td>\n",
       "      <td>1.069181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15700</td>\n",
       "      <td>0.727500</td>\n",
       "      <td>1.066294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>0.648000</td>\n",
       "      <td>1.066074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15900</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>1.067623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.633200</td>\n",
       "      <td>1.067926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16100</td>\n",
       "      <td>0.684600</td>\n",
       "      <td>1.066035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>0.701500</td>\n",
       "      <td>1.065024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16300</td>\n",
       "      <td>0.679700</td>\n",
       "      <td>1.064209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>0.658800</td>\n",
       "      <td>1.064690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.629800</td>\n",
       "      <td>1.069385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>0.633400</td>\n",
       "      <td>1.065570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16700</td>\n",
       "      <td>0.694700</td>\n",
       "      <td>1.067825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.600500</td>\n",
       "      <td>1.064935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16900</td>\n",
       "      <td>0.650300</td>\n",
       "      <td>1.066669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.610300</td>\n",
       "      <td>1.068873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17100</td>\n",
       "      <td>0.647900</td>\n",
       "      <td>1.066616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>0.657800</td>\n",
       "      <td>1.067178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17300</td>\n",
       "      <td>0.666100</td>\n",
       "      <td>1.066751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>0.563900</td>\n",
       "      <td>1.063164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.655000</td>\n",
       "      <td>1.063558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>0.711400</td>\n",
       "      <td>1.063438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17700</td>\n",
       "      <td>0.675600</td>\n",
       "      <td>1.064835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17800</td>\n",
       "      <td>0.612800</td>\n",
       "      <td>1.061924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17900</td>\n",
       "      <td>0.700200</td>\n",
       "      <td>1.064734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.577700</td>\n",
       "      <td>1.065316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18100</td>\n",
       "      <td>0.632200</td>\n",
       "      <td>1.064962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18200</td>\n",
       "      <td>0.646300</td>\n",
       "      <td>1.065302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18300</td>\n",
       "      <td>0.619700</td>\n",
       "      <td>1.066452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18400</td>\n",
       "      <td>0.679800</td>\n",
       "      <td>1.065728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>1.066151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18600</td>\n",
       "      <td>0.670300</td>\n",
       "      <td>1.063755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18700</td>\n",
       "      <td>0.623100</td>\n",
       "      <td>1.064441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18800</td>\n",
       "      <td>0.639400</td>\n",
       "      <td>1.064734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18900</td>\n",
       "      <td>0.651500</td>\n",
       "      <td>1.066804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.624400</td>\n",
       "      <td>1.064882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19100</td>\n",
       "      <td>0.640300</td>\n",
       "      <td>1.064606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>0.648300</td>\n",
       "      <td>1.062358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19300</td>\n",
       "      <td>0.663400</td>\n",
       "      <td>1.063817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19400</td>\n",
       "      <td>0.677600</td>\n",
       "      <td>1.064856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>1.063951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19600</td>\n",
       "      <td>0.617100</td>\n",
       "      <td>1.064096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19700</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>1.063386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19800</td>\n",
       "      <td>0.599900</td>\n",
       "      <td>1.064449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19900</td>\n",
       "      <td>0.598500</td>\n",
       "      <td>1.065993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.753100</td>\n",
       "      <td>1.065757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/30 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "100%|███████████████████████████████████████████| 30/30 [01:50<00:00,  3.70s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 45806.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.0028138222263932766, 'brevity_penalty': 0.30590154455896784, 'ratio': 0.45777233782129745, 'translation_length': 374, 'reference_length': 817, 'precisions_0': 0.056, 'precisions_1': 0.011594202898550725, 'precisions_2': 0.0031645569620253164, 'precisions_3': 0.003484320557491289}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.50s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 150874.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20810517743045512, 'brevity_penalty': 0.7200351241985318, 'ratio': 0.7527539779681762, 'translation_length': 615, 'reference_length': 817, 'precisions_0': 0.5551948051948052, 'precisions_1': 0.36177474402730375, 'precisions_2': 0.22841726618705036, 'precisions_3': 0.1520912547528517}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.51s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 48960.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.23521150037436225, 'brevity_penalty': 0.7246934997419091, 'ratio': 0.7564259485924113, 'translation_length': 618, 'reference_length': 817, 'precisions_0': 0.5573505654281099, 'precisions_1': 0.3938879456706282, 'precisions_2': 0.26475849731663686, 'precisions_3': 0.19092627599243855}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:48<00:00,  3.62s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 155922.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.23638696232851494, 'brevity_penalty': 0.6645662613783451, 'ratio': 0.7099143206854345, 'translation_length': 580, 'reference_length': 817, 'precisions_0': 0.621342512908778, 'precisions_1': 0.426497277676951, 'precisions_2': 0.29366602687140114, 'precisions_3': 0.20570264765784113}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.57s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 161942.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2192294686296193, 'brevity_penalty': 0.6901782584838726, 'ratio': 0.7294981640146879, 'translation_length': 596, 'reference_length': 817, 'precisions_0': 0.5561139028475712, 'precisions_1': 0.37742504409171074, 'precisions_2': 0.25884543761638734, 'precisions_3': 0.1873767258382643}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.55s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 170039.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.22773001714820523, 'brevity_penalty': 0.6774254411055589, 'ratio': 0.7197062423500612, 'translation_length': 588, 'reference_length': 817, 'precisions_0': 0.5959252971137521, 'precisions_1': 0.407871198568873, 'precisions_2': 0.27599243856332706, 'precisions_3': 0.1903807615230461}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:45<00:00,  3.52s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 168671.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2093400464543299, 'brevity_penalty': 0.7075381305279058, 'ratio': 0.7429620563035496, 'translation_length': 607, 'reference_length': 817, 'precisions_0': 0.5444078947368421, 'precisions_1': 0.3546712802768166, 'precisions_2': 0.23905109489051096, 'precisions_3': 0.16602316602316602}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.58s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 55627.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2125711326947317, 'brevity_penalty': 0.5953609846006505, 'ratio': 0.6585067319461444, 'translation_length': 538, 'reference_length': 817, 'precisions_0': 0.5974025974025974, 'precisions_1': 0.4204322200392927, 'precisions_2': 0.2964509394572025, 'precisions_3': 0.2182628062360802}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.57s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 162569.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21909004786713776, 'brevity_penalty': 0.6203967900462553, 'ratio': 0.6768665850673194, 'translation_length': 553, 'reference_length': 817, 'precisions_0': 0.6010830324909747, 'precisions_1': 0.41603053435114506, 'precisions_2': 0.291497975708502, 'precisions_3': 0.21336206896551724}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 141859.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.22067874296130954, 'brevity_penalty': 0.63196038331477, 'ratio': 0.6854345165238678, 'translation_length': 560, 'reference_length': 817, 'precisions_0': 0.6007130124777184, 'precisions_1': 0.4124293785310734, 'precisions_2': 0.29141716566866266, 'precisions_3': 0.2059447983014862}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 42930.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.19696847356049732, 'brevity_penalty': 0.5869397994961546, 'ratio': 0.6523867809057528, 'translation_length': 533, 'reference_length': 817, 'precisions_0': 0.5917602996254682, 'precisions_1': 0.39880952380952384, 'precisions_2': 0.2742616033755274, 'precisions_3': 0.19594594594594594}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:49<00:00,  3.66s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 158875.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.220534521681984, 'brevity_penalty': 0.6629514358413311, 'ratio': 0.7086903304773562, 'translation_length': 579, 'reference_length': 817, 'precisions_0': 0.5655172413793104, 'precisions_1': 0.39636363636363636, 'precisions_2': 0.27884615384615385, 'precisions_3': 0.19591836734693877}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:48<00:00,  3.63s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 39482.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2192560562388062, 'brevity_penalty': 0.7075381305279058, 'ratio': 0.7429620563035496, 'translation_length': 607, 'reference_length': 817, 'precisions_0': 0.5575657894736842, 'precisions_1': 0.3685121107266436, 'precisions_2': 0.25547445255474455, 'precisions_3': 0.17567567567567569}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 48770.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2246996769490805, 'brevity_penalty': 0.6516017749168791, 'ratio': 0.7001223990208079, 'translation_length': 572, 'reference_length': 817, 'precisions_0': 0.5794066317626527, 'precisions_1': 0.40331491712707185, 'precisions_2': 0.28654970760233917, 'precisions_3': 0.2111801242236025}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.54s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 162991.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.19697319347217687, 'brevity_penalty': 0.6901782584838726, 'ratio': 0.7294981640146879, 'translation_length': 596, 'reference_length': 817, 'precisions_0': 0.5309882747068677, 'precisions_1': 0.3562610229276896, 'precisions_2': 0.2309124767225326, 'precisions_3': 0.15187376725838264}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 167772.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21976307427592082, 'brevity_penalty': 0.6645662613783451, 'ratio': 0.7099143206854345, 'translation_length': 580, 'reference_length': 817, 'precisions_0': 0.5731497418244407, 'precisions_1': 0.3956442831215971, 'precisions_2': 0.272552783109405, 'precisions_3': 0.1934826883910387}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.57s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 169352.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.22567287376076783, 'brevity_penalty': 0.6580971081453522, 'ratio': 0.7050183598531212, 'translation_length': 576, 'reference_length': 817, 'precisions_0': 0.5823223570190641, 'precisions_1': 0.40950639853747717, 'precisions_2': 0.28239845261121854, 'precisions_3': 0.2053388090349076}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:48<00:00,  3.63s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 52494.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.22126883576346396, 'brevity_penalty': 0.6385332304644112, 'ratio': 0.6903304773561811, 'translation_length': 564, 'reference_length': 817, 'precisions_0': 0.6017699115044248, 'precisions_1': 0.41869158878504675, 'precisions_2': 0.28316831683168314, 'precisions_3': 0.20210526315789473}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.57s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 164482.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21401714162504726, 'brevity_penalty': 0.6170787554426814, 'ratio': 0.6744186046511628, 'translation_length': 551, 'reference_length': 817, 'precisions_0': 0.5797101449275363, 'precisions_1': 0.4118773946360153, 'precisions_2': 0.2886178861788618, 'precisions_3': 0.20995670995670995}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 159479.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2263903024035063, 'brevity_penalty': 0.6120900220656069, 'ratio': 0.6707466340269278, 'translation_length': 548, 'reference_length': 817, 'precisions_0': 0.6138433515482696, 'precisions_1': 0.4373795761078998, 'precisions_2': 0.3047034764826176, 'precisions_3': 0.22875816993464052}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.58s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 166220.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20821557799189688, 'brevity_penalty': 0.6187385540544988, 'ratio': 0.6756425948592412, 'translation_length': 552, 'reference_length': 817, 'precisions_0': 0.5804701627486437, 'precisions_1': 0.39579349904397704, 'precisions_2': 0.2778904665314402, 'precisions_3': 0.20086393088552915}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.58s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 144134.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.22373485829470582, 'brevity_penalty': 0.6220534596927131, 'ratio': 0.6780905752753978, 'translation_length': 554, 'reference_length': 817, 'precisions_0': 0.6018018018018018, 'precisions_1': 0.42857142857142855, 'precisions_2': 0.29292929292929293, 'precisions_3': 0.221505376344086}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.59s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 50111.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21588654931506668, 'brevity_penalty': 0.5987189659716076, 'ratio': 0.6609547123623011, 'translation_length': 540, 'reference_length': 817, 'precisions_0': 0.6025878003696857, 'precisions_1': 0.42857142857142855, 'precisions_2': 0.29521829521829523, 'precisions_3': 0.22172949002217296}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.57s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 170963.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21502321174892258, 'brevity_penalty': 0.6368924160294538, 'ratio': 0.6891064871481029, 'translation_length': 563, 'reference_length': 817, 'precisions_0': 0.5797872340425532, 'precisions_1': 0.40823970037453183, 'precisions_2': 0.27976190476190477, 'precisions_3': 0.1962025316455696}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 161526.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.22854686908576086, 'brevity_penalty': 0.6418100460327502, 'ratio': 0.6927784577723378, 'translation_length': 566, 'reference_length': 817, 'precisions_0': 0.5731922398589065, 'precisions_1': 0.4171322160148976, 'precisions_2': 0.29980276134122286, 'precisions_3': 0.22431865828092243}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.59s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 152705.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21912348088566602, 'brevity_penalty': 0.6070873651895963, 'ratio': 0.6670746634026927, 'translation_length': 545, 'reference_length': 817, 'precisions_0': 0.5934065934065934, 'precisions_1': 0.42441860465116277, 'precisions_2': 0.29835390946502055, 'precisions_3': 0.22587719298245615}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.57s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 39882.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21141494781180065, 'brevity_penalty': 0.6253620853529512, 'ratio': 0.6805385556915544, 'translation_length': 556, 'reference_length': 817, 'precisions_0': 0.5888689407540395, 'precisions_1': 0.3984819734345351, 'precisions_2': 0.27364185110663986, 'precisions_3': 0.20342612419700215}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.55s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 159681.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2220270724249386, 'brevity_penalty': 0.6613349669059593, 'ratio': 0.7074663402692778, 'translation_length': 578, 'reference_length': 817, 'precisions_0': 0.5630397236614854, 'precisions_1': 0.3989071038251366, 'precisions_2': 0.279383429672447, 'precisions_3': 0.20245398773006135}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.57s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 48507.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21296956795121147, 'brevity_penalty': 0.6237085593295825, 'ratio': 0.6793145654834761, 'translation_length': 555, 'reference_length': 817, 'precisions_0': 0.5809352517985612, 'precisions_1': 0.4011406844106464, 'precisions_2': 0.28024193548387094, 'precisions_3': 0.20815450643776823}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.57s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 160906.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21854010176418737, 'brevity_penalty': 0.6303131865967199, 'ratio': 0.6842105263157895, 'translation_length': 559, 'reference_length': 817, 'precisions_0': 0.5857142857142857, 'precisions_1': 0.41509433962264153, 'precisions_2': 0.288, 'precisions_3': 0.20638297872340425}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:48<00:00,  3.60s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 55553.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21364212372472507, 'brevity_penalty': 0.6037445798285037, 'ratio': 0.6646266829865362, 'translation_length': 543, 'reference_length': 817, 'precisions_0': 0.5900735294117647, 'precisions_1': 0.4182879377431907, 'precisions_2': 0.29132231404958675, 'precisions_3': 0.21806167400881057}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 161734.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21250228265532048, 'brevity_penalty': 0.6070873651895963, 'ratio': 0.6670746634026927, 'translation_length': 545, 'reference_length': 817, 'precisions_0': 0.5787545787545788, 'precisions_1': 0.40891472868217055, 'precisions_2': 0.29218106995884774, 'precisions_3': 0.21710526315789475}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.58s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 161112.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2029416192701593, 'brevity_penalty': 0.6253620853529512, 'ratio': 0.6805385556915544, 'translation_length': 556, 'reference_length': 817, 'precisions_0': 0.5691202872531418, 'precisions_1': 0.3908918406072106, 'precisions_2': 0.2676056338028169, 'precisions_3': 0.18629550321199143}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.58s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 157878.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21555934933771081, 'brevity_penalty': 0.6286644024420278, 'ratio': 0.6829865361077111, 'translation_length': 558, 'reference_length': 817, 'precisions_0': 0.5867620751341681, 'precisions_1': 0.4102079395085066, 'precisions_2': 0.280561122244489, 'precisions_3': 0.2046908315565032}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.57s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 163626.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2075769588838348, 'brevity_penalty': 0.63196038331477, 'ratio': 0.6854345165238678, 'translation_length': 560, 'reference_length': 817, 'precisions_0': 0.5579322638146168, 'precisions_1': 0.3879472693032015, 'precisions_2': 0.2694610778443114, 'precisions_3': 0.19957537154989385}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.57s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 166661.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2219371420704936, 'brevity_penalty': 0.6532280539448486, 'ratio': 0.7013463892288861, 'translation_length': 573, 'reference_length': 817, 'precisions_0': 0.5696864111498258, 'precisions_1': 0.4025735294117647, 'precisions_2': 0.2840466926070039, 'precisions_3': 0.20454545454545456}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.57s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 169581.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2084547186531027, 'brevity_penalty': 0.6286644024420278, 'ratio': 0.6829865361077111, 'translation_length': 558, 'reference_length': 817, 'precisions_0': 0.5688729874776386, 'precisions_1': 0.3931947069943289, 'precisions_2': 0.2725450901803607, 'precisions_3': 0.19829424307036247}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.57s/it]\n",
      "100%|████████████████████████████████████████| 30/30 [00:00<00:00, 41174.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.202709812540591, 'brevity_penalty': 0.6237085593295825, 'ratio': 0.6793145654834761, 'translation_length': 555, 'reference_length': 817, 'precisions_0': 0.552158273381295, 'precisions_1': 0.3916349809885932, 'precisions_2': 0.2701612903225806, 'precisions_3': 0.19098712446351931}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 163626.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20994192552867763, 'brevity_penalty': 0.6580971081453522, 'ratio': 0.7050183598531212, 'translation_length': 576, 'reference_length': 817, 'precisions_0': 0.561525129982669, 'precisions_1': 0.38939670932358317, 'precisions_2': 0.25918762088974856, 'precisions_3': 0.18275154004106775}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.57s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 146312.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20717945438972582, 'brevity_penalty': 0.6253620853529512, 'ratio': 0.6805385556915544, 'translation_length': 556, 'reference_length': 817, 'precisions_0': 0.5547576301615799, 'precisions_1': 0.3984819734345351, 'precisions_2': 0.27364185110663986, 'precisions_3': 0.19914346895074947}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 160496.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20503232433829952, 'brevity_penalty': 0.6450804239336081, 'ratio': 0.6952264381884945, 'translation_length': 568, 'reference_length': 817, 'precisions_0': 0.5729349736379613, 'precisions_1': 0.3914656771799629, 'precisions_2': 0.25343811394891946, 'precisions_3': 0.17954070981210857}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.57s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 163626.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.20205400586294964, 'brevity_penalty': 0.635250001256266, 'ratio': 0.6878824969400245, 'translation_length': 562, 'reference_length': 817, 'precisions_0': 0.5577264653641207, 'precisions_1': 0.38461538461538464, 'precisions_2': 0.25646123260437376, 'precisions_3': 0.18604651162790697}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.58s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 170269.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.21432548948692853, 'brevity_penalty': 0.6368924160294538, 'ratio': 0.6891064871481029, 'translation_length': 563, 'reference_length': 817, 'precisions_0': 0.5762411347517731, 'precisions_1': 0.40262172284644193, 'precisions_2': 0.2757936507936508, 'precisions_3': 0.20042194092827004}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:46<00:00,  3.56s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 161942.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2164318416449623, 'brevity_penalty': 0.6434460411594718, 'ratio': 0.6940024479804161, 'translation_length': 567, 'reference_length': 817, 'precisions_0': 0.5757042253521126, 'precisions_1': 0.4033457249070632, 'precisions_2': 0.27165354330708663, 'precisions_3': 0.20292887029288703}\n",
      "generation_config: GenerationConfig {\n",
      "  \"max_new_tokens\": 30,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 30/30 [01:47<00:00,  3.58s/it]\n",
      "100%|███████████████████████████████████████| 30/30 [00:00<00:00, 159479.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'EM': 0.0, 'BLEU': 0.2027390527718878, 'brevity_penalty': 0.6070873651895963, 'ratio': 0.6670746634026927, 'translation_length': 545, 'reference_length': 817, 'precisions_0': 0.5842490842490843, 'precisions_1': 0.40310077519379844, 'precisions_2': 0.2736625514403292, 'precisions_3': 0.19298245614035087}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# def generate_prompt(data_point):\n",
    "#     # sorry about the formatting disaster gotta move fast\n",
    "#     if data_point[\"input\"]:\n",
    "#         return f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "# ### Instruction:\n",
    "# {data_point[\"instruction\"]}\n",
    "# ### Input:\n",
    "# {data_point[\"input\"]}\n",
    "# ### Response:\n",
    "# {data_point[\"output\"]}\"\"\"\n",
    "#     else:\n",
    "#         return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "# ### Instruction:\n",
    "# {data_point[\"instruction\"]}\n",
    "# ### Response:\n",
    "# {data_point[\"output\"]}\"\"\"\n",
    "\n",
    "\n",
    "data = data.shuffle().map(\n",
    "    lambda data_point: tokenizer(\n",
    "        generate_prompt(data_point),\n",
    "        truncation=experiment_config[\"truncation\"],\n",
    "        max_length=experiment_config[\"CUTOFF_LEN\"],\n",
    "        padding=experiment_config[\"padding\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer_val,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data['eval'],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=experiment_config[\"MICRO_BATCH_SIZE\"],\n",
    "        gradient_accumulation_steps=experiment_config[\"GRADIENT_ACCUMULATION_STEPS\"],\n",
    "        warmup_steps=experiment_config[\"warmup_steps\"],\n",
    "        num_train_epochs=experiment_config[\"EPOCHS\"],\n",
    "        learning_rate=experiment_config[\"LEARNING_RATE\"],\n",
    "        fp16=experiment_config[\"fp16\"],\n",
    "        logging_steps=experiment_config[\"logging_steps\"],        \n",
    "        evaluation_strategy = experiment_config['evaluation_strategy'],\n",
    "        eval_steps=experiment_config[\"eval_steps\"],\n",
    "        output_dir=current_experiment_path,#\"lora-alpaca\",\n",
    "        save_total_limit=experiment_config[\"save_total_limit\"],\n",
    "        save_strategy = experiment_config[\"save_strategy\"],\n",
    "        \n",
    "        save_steps = experiment_config[\"save_steps\"],\n",
    "        seed=experiment_config[\"seed\"],\n",
    "        logging_dir=current_experiment_path,\n",
    "        logging_strategy=experiment_config[\"logging_strategy\"],\n",
    "        report_to=experiment_config[\"report_to\"]\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, \n",
    "                                                               mlm=experiment_config[\"mlm\"]\n",
    "                                                              ),\n",
    "    callbacks = [MyCustomCallback]\n",
    ")\n",
    "model.config.use_cache = experiment_config[\"config_use_cache\"]\n",
    "# print(len(trainer.optimizer.state['found_inf_per_device']))\n",
    "\n",
    "\n",
    "trainer.train(resume_from_checkpoint=experiment_config[\"resume_from_checkpoint\"])\n",
    "\n",
    "model.save_pretrained(current_experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac663873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 't2c_concode_220428_v22',\n",
       " 'fn_train_dataset': '/root/data/t2c_train.json',\n",
       " 'fn_eval_dataset': '/root/data/t2c_answers.json',\n",
       " 'default_model': 'decapoda-research/llama-7b-hf',\n",
       " 'MICRO_BATCH_SIZE': 2,\n",
       " 'BATCH_SIZE': 10,\n",
       " 'EPOCHS': 2,\n",
       " 'LEARNING_RATE': 0.0002,\n",
       " 'CUTOFF_LEN': 256,\n",
       " 'LORA_R': 64,\n",
       " 'LORA_ALPHA': 64,\n",
       " 'LORA_DROPOUT': 0.05,\n",
       " 'warmup_steps': 200,\n",
       " 'fp16': True,\n",
       " 'logging_steps': 10,\n",
       " 'eval_steps': 100,\n",
       " 'evaluation_strategy': 'steps',\n",
       " 'save_total_limit': 1,\n",
       " 'save_strategy': 'steps',\n",
       " 'save_steps': 500,\n",
       " 'seed': 42,\n",
       " 'logging_strategy': 'steps',\n",
       " 'report_to': 'tensorboard',\n",
       " 'mlm': False,\n",
       " 'truncation': True,\n",
       " 'padding': 'max_length',\n",
       " 'config_use_cache': False,\n",
       " 'resume_from_checkpoint': False,\n",
       " 'bleu_batch_size': 5,\n",
       " 'GRADIENT_ACCUMULATION_STEPS': 5,\n",
       " 'log_bleu_steps_factor': 50}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "665c1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(current_experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e72383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f14bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!df -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah {current_experiment_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_experiment_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d411735",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah /root/experiments/t2c_concode_220428_v20/checkpoint-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah /root/experiments/t2c_concode_220428_v20/checkpoint-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dca9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf /root/experiments/t2c_concode_220428_v19/checkpoint-20000/\n",
    "# !df -h ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97279e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf {current_experiment_path}/checkpoint-1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feedd63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "print(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a22c54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731023f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
